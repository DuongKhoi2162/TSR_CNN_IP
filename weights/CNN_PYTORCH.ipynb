{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import thư viện\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from torch.quantization.observer import MovingAverageMinMaxObserver\n",
    "from fixedpoint import FixedPoint\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chay class bo datashet dung duong dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.11).\n",
      "Path to dataset files: C:\\Users\\lckd2\\.cache\\kagglehub\\datasets\\meowmeowmeowmeowmeow\\gtsrb-german-traffic-sign\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "veri_path = 'C:\\\\Users\\\\lckd2\\\\.cache\\\\kagglehub\\\\datasets\\\\meowmeowmeowmeowmeow\\\\gtsrb-german-traffic-sign\\\\versions\\\\1'\n",
    "train_path = os.path.join(veri_path, 'Train')\n",
    "number_of_class = len(os.listdir(train_path))\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 40, 30, 30]           1,120\n",
      "         MaxPool2d-2           [-1, 40, 15, 15]               0\n",
      "            Conv2d-3           [-1, 20, 15, 15]             820\n",
      "            Conv2d-4           [-1, 48, 13, 13]           8,688\n",
      "            Conv2d-5           [-1, 24, 13, 13]           1,176\n",
      "            Conv2d-6           [-1, 48, 11, 11]          10,416\n",
      "         MaxPool2d-7             [-1, 48, 5, 5]               0\n",
      "            Conv2d-8             [-1, 24, 5, 5]           1,176\n",
      "            Conv2d-9             [-1, 48, 3, 3]          10,416\n",
      "           Conv2d-10             [-1, 32, 3, 3]           1,568\n",
      "           Conv2d-11             [-1, 64, 1, 1]          18,496\n",
      "          Dropout-12             [-1, 64, 1, 1]               0\n",
      "           Linear-13                   [-1, 43]           2,795\n",
      "================================================================\n",
      "Total params: 56,671\n",
      "Trainable params: 56,671\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.54\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 0.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "class TrafficSignModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignModel, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=40, kernel_size=(3, 3), padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=40, out_channels=20, kernel_size=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "        self.conv4 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "        \n",
    "        # Pooling Layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        # Affine Layer\n",
    "        self.conv6 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1))\n",
    "        self.conv7 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "        self.conv8 = nn.Conv2d(in_channels=48, out_channels=32, kernel_size=(1, 1))\n",
    "        self.conv9 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.fc = nn.Linear(64 * 1 * 1, 43)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "        outputs['image'] = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        outputs['conv1'] = x\n",
    "        x = self.pool1(x)\n",
    "        outputs['pool1'] = x\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        outputs['conv2'] = x\n",
    "        x = self.conv3(x)\n",
    "        outputs['conv3'] = x\n",
    "        x = self.conv4(x)\n",
    "        outputs['conv4'] = x\n",
    "        x = F.relu(self.conv5(x))\n",
    "        outputs['conv5'] = x\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        outputs['pool2'] = x\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        outputs['conv6'] = x\n",
    "        x = self.conv7(x)\n",
    "        outputs['conv7'] = x\n",
    "        x = self.conv8(x)\n",
    "        outputs['conv8'] = x\n",
    "        x = F.relu(self.conv9(x))\n",
    "        outputs['conv9'] = x\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 1 * 1)  # Flatten the tensor\n",
    "        outputs['flatten'] = x\n",
    "        x = self.fc(x)\n",
    "        outputs['fc'] = x\n",
    "\n",
    "        # Dequantize the output\n",
    "        outputs['output'] = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "model = TrafficSignModel()\n",
    "import torchsummary as ts\n",
    "ts.summary(model,(3,32,32))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chay class quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QuantizedTrafficSignModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedTrafficSignModel, self).__init__()\n",
    "\n",
    "        # Quantization stubs\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=40, kernel_size=(3, 3), padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=40, out_channels=20, kernel_size=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "        self.conv4 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "\n",
    "        # Pooling Layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        # Affine Layer\n",
    "        self.conv6 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1))\n",
    "        self.conv7 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=0)\n",
    "        self.conv8 = nn.Conv2d(in_channels=48, out_channels=32, kernel_size=(1, 1))\n",
    "        self.conv9 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=0)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "        # Output Layer\n",
    "        self.fc = nn.Linear(64 * 1 * 1, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Quantize the input\n",
    "        x = self.quant(x)\n",
    "\n",
    "        # Forward pass through the layers\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(self.conv9(x))\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 1 * 1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # Dequantize the output\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedTrafficSignModel_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedTrafficSignModel_1, self).__init__()\n",
    "\n",
    "        # Quantization stubs\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=40, kernel_size=(3, 3), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride = (2,2), padding=(0,0), dilation = (1,1))\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=40, out_channels=20, kernel_size=(1, 1), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=48, kernel_size=(3, 3), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv4 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "\n",
    "        # Pooling Layer 2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=(0,0), stride=(2,2), dilation=(1,1))\n",
    "\n",
    "        # Affine Layer\n",
    "        self.conv6 = nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(1, 1), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv7 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=(3, 3), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv8 = nn.Conv2d(in_channels=48, out_channels=32, kernel_size=(1, 1), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.conv9 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=(0,0), stride=(1,1), dilation=(1,1))\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "\n",
    "        # Output Layer\n",
    "        self.fc = nn.Linear(64 * 1 * 1, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "        outputs['input'] = x\n",
    "        # Quantize the input\n",
    "        x = self.quant(x)\n",
    "        outputs['image'] = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        outputs['conv1'] = x\n",
    "        x = self.pool1(x)\n",
    "        outputs['pool1'] = x\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        outputs['conv2'] = x\n",
    "        x = self.conv3(x)\n",
    "        outputs['conv3'] = x\n",
    "        x = self.conv4(x)\n",
    "        outputs['conv4'] = x\n",
    "        x = F.relu(self.conv5(x))\n",
    "        outputs['conv5'] = x\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        outputs['pool2'] = x\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        outputs['conv6'] = x\n",
    "        x = self.conv7(x)\n",
    "        outputs['conv7'] = x\n",
    "        x = self.conv8(x)\n",
    "        outputs['conv8'] = x\n",
    "        x = F.relu(self.conv9(x))\n",
    "        outputs['conv9'] = x\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 64 * 1 * 1)  # Flatten the tensor\n",
    "        outputs['flatten'] = x\n",
    "        x = self.fc(x)\n",
    "        outputs['fc'] = x\n",
    "\n",
    "        # Dequantize the output\n",
    "        x = self.dequant(x)\n",
    "        outputs['output'] = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(veri_path+'\\\\Test.csv')\n",
    "imgs = test[\"Path\"].values\n",
    "classIds = test[\"ClassId\"].values\n",
    "test_images = []\n",
    "\n",
    "for img in imgs:\n",
    "    image = cv2.imread(os.path.join(veri_path, img))\n",
    "    image = cv2.resize(image, (32, 32))\n",
    "    test_images.append(image)\n",
    "\n",
    "X_test = np.array(test_images)\n",
    "y_test = np.eye(number_of_class)[classIds]\n",
    "test_dataset = TrafficSignDataset(X_test, y_test, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([22, 3, 32, 32])\n",
      "Accuracy of the quantized model on the test set: 95.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.55819477434679"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_quantized_model(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['output']\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the quantized model on the test set: {accuracy:.1f}%')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "test_quantized_model(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_model(model, data_loader):\n",
    "    model.eval()\n",
    "    model.qconfig = torch.quantization.QConfig(\n",
    "        activation=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.quint8),\n",
    "        weight=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_symmetric, dtype=torch.qint8)\n",
    "    )\n",
    "    print(model.qconfig)\n",
    "    model_prepared = torch.quantization.prepare(model)\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            model_prepared(images.float())\n",
    "    \n",
    "    model_quantized = torch.quantization.convert(model_prepared)\n",
    "    return model_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bo vo chung duong dan roi chay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_symmetric, dtype=torch.quint8){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_symmetric, dtype=torch.qint8){})\n",
      "Accuracy of the quantized model on the test set: 95.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.55819477434679"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = 'traffic_sign_model.pth'\n",
    "quantized_checkpoint_path = 'quant_traffic_sign_model.pth'\n",
    "model = QuantizedTrafficSignModel_1()\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "model = quantize_model(model, test_loader)\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), quantized_checkpoint_path)\n",
    "test_quantized_model(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_symmetric, dtype=torch.quint8){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_symmetric, dtype=torch.qint8){})\n",
      "QuantizedTrafficSignModel_1(\n",
      "  (quant): Quantize(scale=tensor([0.0078]), zero_point=tensor([128]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      "  (conv1): QuantizedConv2d(3, 40, kernel_size=(3, 3), stride=(1, 1), scale=0.037425290793180466, zero_point=128)\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), scale=0.0313236266374588, zero_point=128)\n",
      "  (conv3): QuantizedConv2d(20, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.04970667511224747, zero_point=128)\n",
      "  (conv4): QuantizedConv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.1507696509361267, zero_point=128)\n",
      "  (conv5): QuantizedConv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.34373271465301514, zero_point=128)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv6): QuantizedConv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.256680428981781, zero_point=128)\n",
      "  (conv7): QuantizedConv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.3495754599571228, zero_point=128)\n",
      "  (conv8): QuantizedConv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.4974721372127533, zero_point=128)\n",
      "  (conv9): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0013073682785034, zero_point=128)\n",
      "  (dropout): QuantizedDropout(p=0.15, inplace=False)\n",
      "  (fc): QuantizedLinear(in_features=64, out_features=43, scale=1.2371432781219482, zero_point=128, qscheme=torch.per_tensor_affine)\n",
      ")\n",
      "tensor([16,  1, 38, 33, 11, 38, 18, 12, 25, 35, 12,  7, 23,  7,  4,  9, 21, 20,\n",
      "        27, 38,  4, 33,  9,  3,  1, 11, 13, 10,  9, 11,  5, 17])\n",
      "tensor([34, 19,  2, 17,  3, 12, 16,  8,  7, 30, 18, 12, 30, 25,  3, 10, 18,  1,\n",
      "        37, 13, 15,  9, 13, 35,  5, 26,  9, 16, 38, 10,  4,  9])\n",
      "tensor([15,  9, 18,  2,  5, 28, 11, 25, 11, 34,  5, 12,  1, 10, 23, 10, 21, 33,\n",
      "        25,  7, 10, 35,  3,  7, 22, 13,  3,  1,  2, 14, 12, 32])\n",
      "tensor([ 3, 38,  9, 33,  1, 10,  5, 11, 33,  4, 35, 25, 33,  4,  1, 14, 16, 10,\n",
      "        11,  3, 27, 29,  1, 17, 13,  7,  1,  8,  2, 10, 10, 24])\n",
      "tensor([ 1,  6, 36,  3, 14, 13, 11, 10, 18, 40,  2, 38, 41,  4,  6, 18, 17, 25,\n",
      "         2,  9, 11, 21,  7, 24, 11, 25, 17,  3,  6,  9,  7,  4])\n",
      "tensor([13, 16,  4, 24, 18,  9, 13, 14, 29, 17, 13, 38, 26, 25, 33,  1,  3, 40,\n",
      "        13,  2,  8,  4, 36, 25, 20, 25, 18,  1, 10,  8, 10, 29])\n",
      "tensor([12, 38, 31,  2,  8, 38, 11, 28, 17,  9,  4,  1, 17,  9,  2, 31, 13, 15,\n",
      "        15, 38, 25,  5, 25, 13, 10,  5,  4, 10,  2,  4,  5,  1])\n",
      "tensor([14, 12, 12,  5,  8, 36, 25, 13, 33, 18, 33, 19, 12, 28,  4, 18, 12, 13,\n",
      "        20,  0, 10, 40,  5,  8, 12, 38, 20, 14,  1, 36, 34, 28])\n",
      "tensor([35, 13, 25, 15, 35, 14, 18, 25,  1, 15,  5, 25,  2, 18, 18, 18, 34,  9,\n",
      "        25, 18, 34, 39, 31,  1,  9, 35, 31, 18,  1,  1, 33, 30])\n",
      "tensor([17, 13,  1, 31, 13, 35,  5,  1, 33, 28, 35, 26, 12,  5,  2, 14,  5,  3,\n",
      "        32,  1,  7, 38, 19, 11, 38, 38,  2, 42,  2, 40, 17,  4])\n",
      "tensor([ 8,  4,  5,  6, 31, 35,  9, 38,  8,  2,  4, 18,  3, 25, 10,  5,  7, 34,\n",
      "         4, 22, 10, 29,  9,  2, 38, 38, 18,  7, 13, 28, 17,  2])\n",
      "tensor([16, 14, 12, 40, 35,  3, 38, 10,  9, 38, 13, 39,  3, 11,  7, 38, 19, 13,\n",
      "        10, 18,  3,  5, 25,  1, 41, 13,  1, 18, 19, 13, 38,  4])\n",
      "tensor([35, 25, 34, 12, 17,  9,  4, 33, 28,  2,  1,  5,  4, 38,  4, 12, 38, 36,\n",
      "        10,  0, 38, 36,  8, 25,  5,  2, 25, 14,  2, 26, 29, 10])\n",
      "tensor([10, 14,  9,  2,  3,  2, 19,  9, 10, 13, 13, 20, 38, 34, 11, 13, 34, 34,\n",
      "        12,  6, 10, 10,  8,  3, 22, 17,  7, 28, 25,  1, 31, 38])\n",
      "tensor([38,  8,  9, 10,  2, 40,  1, 36, 14,  8, 39, 32, 35, 25, 25, 17,  2, 38,\n",
      "         7, 13, 14,  7,  8, 35,  3,  1, 35,  9, 35, 36, 24, 13])\n",
      "tensor([33,  2, 35,  6,  2, 10, 12, 31,  9, 14, 17, 26,  7,  3, 10,  5, 11,  9,\n",
      "        31, 40, 22, 23,  9,  7, 23,  4, 32, 42,  1,  3,  8,  2])\n",
      "tensor([25, 22, 38, 33,  3,  1,  8,  4, 18, 26, 31, 14, 11, 13,  3,  2, 18,  4,\n",
      "        13, 15, 23,  1, 12, 31, 38,  5, 10, 35,  8,  6,  5, 12])\n",
      "tensor([ 4,  1,  1,  1, 12, 12,  5,  5,  9, 13, 38,  4, 13,  8, 13, 24, 17, 10,\n",
      "        10, 18, 12, 23, 10, 10,  1, 23,  3,  8, 41,  6, 13, 33])\n",
      "tensor([ 3,  2, 13,  0, 17, 10,  7,  1, 35, 10,  2, 30,  5,  5, 35, 13, 16, 17,\n",
      "        11,  3,  2, 29,  2, 27,  2, 11,  4, 19,  3,  9,  7, 38])\n",
      "tensor([28,  9, 27, 41,  1, 29, 11, 10, 25,  1, 10, 38, 30, 14,  1, 12,  7, 13,\n",
      "        28,  8,  2, 17,  5, 35, 25,  8,  4,  7, 16, 31, 17,  9])\n",
      "tensor([ 7,  8, 17, 11,  2, 13, 12,  7,  1,  2, 32, 17, 13,  5, 12, 11, 29, 13,\n",
      "        13, 10, 10, 35,  2,  7, 13, 10, 14, 13, 11,  4, 15, 10])\n",
      "tensor([36, 35, 26,  0, 25, 18, 29,  8, 13, 14, 35, 12, 35, 35, 14, 25, 17, 34,\n",
      "         5,  4,  4, 13, 29,  4,  5,  8,  1,  2,  3,  4, 39, 12])\n",
      "tensor([ 7, 16, 12, 12, 18, 16,  2, 36, 11, 39,  4,  6,  2, 36,  1,  5, 10, 13,\n",
      "         5, 30, 38, 13, 14, 11, 11, 35, 25,  2, 14, 38, 15, 38])\n",
      "tensor([39, 38,  4,  1,  3,  1, 35, 17,  4, 17,  4,  2,  5, 23, 10, 28,  9, 28,\n",
      "        22, 42,  2, 12,  3, 23,  3, 13, 10,  3, 40,  4,  1,  5])\n",
      "tensor([ 3,  9, 10,  4, 13, 28,  3,  4, 15, 15,  0, 33,  2, 39, 12, 38,  7, 10,\n",
      "         2, 10,  2, 38,  2,  5,  1,  3,  1, 42, 15, 15,  4, 15])\n",
      "tensor([38, 25,  5,  5, 40,  2, 18,  0, 17,  0, 26, 31,  4, 13, 17,  1, 11,  8,\n",
      "         1,  2,  4, 14,  3,  4, 25,  4, 15,  2, 38, 11, 37,  7])\n",
      "tensor([ 1, 18, 28, 11, 10,  9, 15, 11, 12, 10, 13, 13, 25,  4,  1, 38, 12, 23,\n",
      "        10,  2,  1, 29, 24, 10,  1, 28,  5, 11,  5,  6,  9,  2])\n",
      "tensor([ 1, 33,  3,  9, 25, 16, 42, 35, 10, 28,  4,  1,  7,  5,  3, 23,  1,  1,\n",
      "        10, 23, 35, 24, 33,  1, 12,  2, 13, 13, 33, 17, 35,  5])\n",
      "tensor([15, 31, 33, 42, 11, 24, 38,  4, 27,  7, 13, 21, 38, 38,  1, 13, 23, 13,\n",
      "         1, 13, 13, 38, 35,  5, 12, 25,  4,  1, 19,  3,  9,  2])\n",
      "tensor([ 3, 17, 38,  5,  5, 38,  1, 11, 31,  2, 42, 12, 35, 29, 38,  4, 38, 10,\n",
      "        13,  1, 34, 22, 12, 31, 15, 13, 31,  1, 42, 36,  7, 20])\n",
      "tensor([27, 15, 12, 14, 10,  5, 32,  3,  7, 13, 12,  7, 13,  4, 10,  8, 23, 10,\n",
      "        39,  2, 13,  7,  1,  5, 31, 10,  5, 31,  7, 39,  0, 23])\n",
      "tensor([ 7, 38, 35, 38, 25, 38,  9, 16, 17,  1, 12, 12, 10,  5, 38,  3, 40, 12,\n",
      "         8, 10,  2, 10, 12, 35, 15,  4, 35,  5, 14,  1, 11, 35])\n",
      "tensor([38, 25, 11,  4, 12,  1, 18,  8, 11, 41, 10,  2,  8,  2, 35, 13, 38,  9,\n",
      "        12,  7, 12, 31,  2, 11, 17, 35,  4, 18,  4, 34, 40, 11])\n",
      "tensor([11, 33, 15, 13,  5, 12, 13, 13, 12, 15, 31, 32,  4, 41,  8,  2,  8, 39,\n",
      "        14, 42,  4,  7, 11, 11,  2,  2, 13, 10,  2,  8, 18,  4])\n",
      "tensor([ 5,  4, 16, 33,  1, 18, 31, 37, 30,  9, 18,  5, 35, 20,  2, 20, 23,  5,\n",
      "         8,  9, 38, 12, 35,  5, 11, 10, 12, 33,  8, 38,  3, 32])\n",
      "tensor([31,  9, 35, 40, 13,  7, 12,  8, 13,  1, 13,  7, 40,  4,  4,  5, 17, 18,\n",
      "        12, 35,  8, 33,  3, 15, 12, 14,  9,  4,  5, 31, 32,  3])\n",
      "tensor([25,  1, 10, 33,  4, 35,  9,  1, 32,  4, 13, 17,  4,  6, 26, 38,  2, 20,\n",
      "        11,  9, 38, 34, 38, 39,  1, 18,  5,  9, 26, 17, 31, 24])\n",
      "tensor([37, 12, 22,  5,  8, 12, 10,  2,  2, 10,  7, 10, 14,  9,  8, 14,  2,  5,\n",
      "        25,  4,  3, 29, 40, 16, 35, 11, 31, 12, 39, 12, 30, 12])\n",
      "tensor([13,  9,  9, 11, 13, 17, 29, 14, 17, 26,  1, 13, 11, 10,  5,  5,  4,  4,\n",
      "         3, 34, 23,  4,  7, 14, 12, 22, 37, 35, 12, 28, 28,  2])\n",
      "tensor([ 3, 12, 10,  1,  8, 17, 37, 12, 31, 11,  9,  5,  5,  8,  9,  5, 10, 38,\n",
      "        42, 18,  2, 14,  2, 12,  3,  2, 42,  8, 25, 14,  5,  0])\n",
      "tensor([ 2,  1, 14, 36, 11, 13, 11, 10,  8, 34,  4, 38, 14,  2,  7, 17, 29, 33,\n",
      "        28,  7, 38, 18, 14,  1, 33, 16,  4, 19, 23,  6,  5,  8])\n",
      "tensor([ 8, 10, 34, 35,  5,  5, 13, 35, 38,  9, 15,  5, 14, 26, 42, 26, 13, 17,\n",
      "        10,  4,  4,  9,  1,  2, 34,  1, 42, 31, 13,  9, 13, 12])\n",
      "tensor([38,  8, 35, 38,  7,  2,  5, 12, 25,  8,  2, 12, 28, 12,  2,  2, 26,  3,\n",
      "         8, 11,  8, 10, 12,  5, 40,  2, 33, 25,  2, 41, 16, 18])\n",
      "tensor([ 8,  3, 34, 31,  9,  9, 13, 38,  7,  4,  4, 13, 12, 18,  4, 38, 25,  5,\n",
      "         2, 42, 13, 35, 10, 12, 33, 13, 31,  2, 38, 10, 13, 17])\n",
      "tensor([12,  1, 15,  7, 18, 34, 38, 12,  3,  3,  4, 12, 12, 10, 24, 14, 12, 14,\n",
      "        10,  4, 17,  7, 13, 11, 17,  8, 23, 18, 11, 38, 10, 10])\n",
      "tensor([ 6, 25, 18,  4, 11, 31, 12,  1,  8, 12, 35, 11,  5,  4,  2, 18, 38,  5,\n",
      "        38, 13, 10,  3, 42, 34, 31, 26,  8,  5,  7, 20, 15,  2])\n",
      "tensor([ 3, 10, 13,  1,  2,  3,  4, 31, 25, 13,  1,  2,  8, 12,  2, 32, 12, 13,\n",
      "        12,  2,  5,  5,  7, 34, 38,  7,  2,  8,  2,  8,  8,  9])\n",
      "tensor([ 7, 13,  1,  5, 38, 17,  5, 10, 18, 13, 11,  1,  3, 42, 16,  0,  8,  8,\n",
      "        17, 13, 23, 18, 38,  2, 12, 38, 13,  1, 11, 14,  5,  3])\n",
      "tensor([38, 39,  5, 25, 10, 29,  3,  9, 25, 38,  2,  5, 25, 25, 13, 10,  5,  3,\n",
      "        38,  1,  4, 28,  2, 20, 42,  2, 38, 38, 22,  1, 25, 10])\n",
      "tensor([ 2,  5, 17,  1, 20,  5,  9, 38, 38, 28,  3, 28,  6, 13, 30,  1,  2,  7,\n",
      "        17, 35, 14, 13, 10, 38, 17, 10, 11,  8, 15, 25,  2,  4])\n",
      "tensor([38,  6,  1, 25,  7,  8, 18,  3,  8, 13, 16, 23, 42, 16, 12,  2,  9, 32,\n",
      "        12,  2,  7,  7, 38, 12,  7, 25, 38, 38, 31,  9, 11, 10])\n",
      "tensor([25, 12, 20,  5, 10,  2, 23,  9, 33, 13, 35, 19,  8,  5, 34,  9, 10,  1,\n",
      "        35, 17, 13, 10, 38, 13,  7, 26, 12, 14,  7, 28, 17, 31])\n",
      "tensor([ 2, 25, 16,  6, 12, 38, 17, 10,  9,  7, 15, 22,  7,  1, 38, 13, 13, 25,\n",
      "        17, 23, 31, 38,  7, 38,  1, 25,  7, 34,  9, 17,  5, 26])\n",
      "tensor([17, 30, 38, 27,  6,  5, 32, 25, 16, 35, 18,  7,  8, 31,  1,  1, 40, 23,\n",
      "        42, 10,  9, 10, 11, 10, 10, 13, 13, 15, 12, 38, 10, 40])\n",
      "tensor([31,  4,  2, 33, 18,  1,  2, 12,  4, 15, 17, 10, 13, 36, 25,  2, 10,  5,\n",
      "        39, 12,  8, 38, 26, 20, 31, 18, 38,  5,  9,  7, 36, 11])\n",
      "tensor([20, 37, 17,  9, 23, 34, 14,  2,  1, 18,  3,  3, 39, 10,  4, 12, 11,  3,\n",
      "        35, 35, 33, 38,  8, 10, 35, 25, 31,  5,  1,  7, 40, 11])\n",
      "tensor([38,  8, 25, 12, 14, 31,  7,  9, 13, 22, 24,  7, 11, 28, 38, 16,  9, 35,\n",
      "        12,  4, 40,  9, 36, 10,  8, 18, 13,  5,  5, 28, 13, 35])\n",
      "tensor([30,  4, 14, 23, 35, 38,  7,  5,  5, 16,  4,  2, 15,  4, 17, 35, 27, 33,\n",
      "         2, 29,  1, 11,  4, 10, 14, 13, 35, 28, 13,  0, 29,  5])\n",
      "tensor([24, 12, 10, 38,  9, 42,  5,  1, 13, 21,  9, 33, 25, 25, 10, 33,  9, 12,\n",
      "        14, 38, 38,  2,  7, 25,  5, 15, 12,  1,  5,  1, 18,  8])\n",
      "tensor([16, 39, 13, 10,  1,  4,  2, 17, 23,  9, 12, 38, 10, 10, 31,  2, 36, 38,\n",
      "         2, 31, 38,  8, 20, 25,  9, 38, 34, 38, 29, 16, 25, 35])\n",
      "tensor([ 8, 22,  5, 13,  4, 11, 34, 31, 25,  1, 13,  8,  1, 12,  2, 17,  8, 23,\n",
      "         5,  5,  5, 15,  1, 10, 11,  8, 25, 18, 17, 10, 15, 25])\n",
      "tensor([ 5,  4,  4,  1,  4,  7, 40, 11,  1, 20, 17, 26, 38, 12,  7,  4,  1, 40,\n",
      "         9,  9,  5,  1, 34, 12, 30, 12, 10,  3, 10, 17, 10,  7])\n",
      "tensor([10, 25,  2, 22,  8, 38,  7,  2, 22, 11, 11, 13, 35, 12,  3,  3, 34, 38,\n",
      "         3, 11,  9, 26, 17,  2,  4, 35, 36, 12, 38, 10, 22, 38])\n",
      "tensor([ 8,  7,  9, 17,  3, 25,  7,  1,  1,  5,  1, 38,  4, 25, 10,  7, 38, 13,\n",
      "        14, 35, 26, 35, 25, 12, 13,  4,  7,  1,  3,  0, 38,  7])\n",
      "tensor([ 2, 13, 39,  1, 25,  3, 27,  1, 32, 38, 12,  9, 14,  9,  2,  2,  5, 18,\n",
      "        11, 12, 15, 25, 11, 12, 30,  1,  9, 18, 33,  7, 38, 17])\n",
      "tensor([ 2,  9, 15, 13, 10, 31, 28, 18,  1, 13, 31, 28,  9, 11, 25, 37, 25, 12,\n",
      "        18,  1, 29, 31,  7,  2,  2,  6,  7,  4, 36,  1,  2, 17])\n",
      "tensor([25,  5,  2, 13, 26,  7,  9,  3, 13, 18, 11, 13, 11, 13, 10,  5, 16, 13,\n",
      "        16,  9,  3, 16, 13, 35, 13, 10, 36,  1, 38, 17, 12, 11])\n",
      "tensor([ 2,  4, 13, 18, 12, 33, 11, 36, 31,  7, 20,  5, 10, 11,  3, 40,  0,  4,\n",
      "         9,  2,  2,  2, 13, 16, 13,  2, 18,  2, 18,  6,  9,  2])\n",
      "tensor([17, 14,  5, 12,  5, 26,  3, 17, 40, 38, 14, 16,  5,  8,  4,  1,  4, 11,\n",
      "         5, 13,  2, 11, 12,  4,  7, 38, 33, 10, 33, 12, 14, 38])\n",
      "tensor([ 1, 23,  7, 27, 35, 10,  4,  1, 11, 35, 42, 28,  7, 12,  5, 18, 35, 17,\n",
      "         4,  8, 25, 17, 14,  8, 15, 10,  5,  8,  6, 14, 10, 35])\n",
      "tensor([ 1, 13, 22, 16,  1, 35,  5, 13, 38,  7,  1,  4, 25, 11,  3, 12,  2, 12,\n",
      "        15, 10, 10, 13,  6, 23, 13, 25,  2, 12, 13,  2, 12, 13])\n",
      "tensor([ 4, 16, 20, 40, 25, 10,  1,  7, 38,  5, 13,  9,  4, 38, 10, 17, 30, 13,\n",
      "         1, 14, 10, 10, 33,  2, 13,  2,  7, 36,  6,  1, 12, 17])\n",
      "tensor([17,  1,  4,  1, 34,  3,  5, 35,  1,  1,  4, 13, 21, 25,  3,  7,  5,  3,\n",
      "         7,  2,  5, 15, 19,  2, 10, 14, 28, 38, 42, 36, 17,  1])\n",
      "tensor([ 1, 38,  8, 16,  7, 13, 40,  1, 25, 32,  5, 29,  4, 13, 35, 33,  5,  4,\n",
      "        10, 18,  1, 11, 33, 10, 30, 30,  5, 31, 12,  2,  2,  1])\n",
      "tensor([ 8, 13, 12,  2,  1, 25,  8, 33,  4, 17, 25, 15, 26, 11,  2,  7, 22, 10,\n",
      "         4, 25, 31, 10, 18,  1, 11, 17,  7,  2, 24,  5,  7,  5])\n",
      "tensor([28, 12,  8, 23, 38,  1, 34, 23,  2,  8, 38,  9, 38,  8, 25, 13, 38, 13,\n",
      "         4, 31, 12,  8, 31, 22,  6, 25, 10, 33, 38,  1,  4, 12])\n",
      "tensor([35, 25,  5, 11, 13,  7, 14,  8, 11,  1, 11, 17, 35,  4, 18,  6, 19,  9,\n",
      "        11, 35, 38, 25,  2,  9, 13,  2, 13, 18, 11, 38, 10,  2])\n",
      "tensor([ 9, 12,  2,  9,  5,  1, 10, 25,  2, 38, 16, 38, 23, 12, 12, 31,  6, 11,\n",
      "        25, 17, 25, 36,  9, 40, 13, 25,  4,  9, 22,  2,  1, 13])\n",
      "tensor([ 3,  4, 38, 12, 32, 12, 23, 39, 35, 31, 40,  2,  9,  5,  8, 20,  5,  9,\n",
      "         2, 11, 12, 29, 17,  8,  3, 15,  3, 13, 10, 13,  4,  1])\n",
      "tensor([25,  5, 26, 25, 10,  1,  8, 40,  9, 10,  5, 25, 25, 12, 10, 13, 39, 17,\n",
      "         7, 17,  9, 12,  1,  9, 10,  4,  9, 18,  7,  4,  1, 19])\n",
      "tensor([ 2,  4, 35, 11,  9,  5,  2,  7, 25, 14, 26, 23,  5, 18,  2, 29, 25,  5,\n",
      "        22, 12,  1, 14, 34, 33, 19,  2, 12,  9, 17, 26, 13, 14])\n",
      "tensor([ 3,  2,  2,  5, 17, 25, 17, 30, 30, 10, 35,  4,  2,  2, 28, 33, 33, 33,\n",
      "        27, 24, 25,  9, 16, 18,  1,  5, 34, 10, 25, 25, 35,  5])\n",
      "tensor([13,  5,  7,  4, 34, 15,  7, 13,  1, 23, 35,  5, 13,  5, 28, 13, 12, 11,\n",
      "        25, 34, 10,  3,  5, 31, 11, 11, 37, 12, 25,  9, 13, 30])\n",
      "tensor([25, 25, 12, 12, 30, 15, 13,  1, 25,  8, 13,  3, 10, 18, 42,  9, 16,  4,\n",
      "        12, 15, 25,  6,  9,  1,  1,  2, 30, 13, 33, 38,  4, 20])\n",
      "tensor([ 7,  2, 35, 10, 38,  4,  1, 13, 11, 38,  7,  5,  5, 35, 37, 38, 38,  1,\n",
      "        33, 29, 26, 25, 25, 10,  1,  1,  1, 16,  5, 23, 10,  9])\n",
      "tensor([17,  2, 12,  9, 18, 35, 10,  2, 15, 12,  4, 25, 10, 12,  5, 13,  2,  3,\n",
      "        28,  1, 23,  1,  1,  9,  5, 38, 12,  1, 11, 13,  9, 24])\n",
      "tensor([ 0, 10, 38,  5,  4, 18,  5, 36, 30, 10, 38, 16,  2, 31, 24, 38, 25, 17,\n",
      "        12, 29,  4, 10, 14, 11, 25, 18,  4,  4,  8, 25, 18,  7])\n",
      "tensor([38,  3, 13, 31,  8, 21, 31, 38,  2,  2, 34, 10,  7, 10, 38,  8,  4, 12,\n",
      "        28,  5, 39, 41, 10, 13, 38, 38, 19,  1,  8,  6, 39,  3])\n",
      "tensor([ 1, 19, 32, 38, 12,  8, 35, 12, 38, 17,  2,  1, 14, 35, 12, 35, 34, 17,\n",
      "        42,  1,  1, 31,  6, 28, 12, 38, 11,  5,  8,  8, 23,  1])\n",
      "tensor([ 2,  1, 25, 10, 31,  3, 18, 18, 13, 18, 13, 34,  5,  4,  1, 23, 28,  4,\n",
      "        12,  1, 38,  1, 12, 25, 14, 38,  1, 17,  9, 16, 13,  7])\n",
      "tensor([39,  2,  8,  2, 10, 25, 26,  2,  4, 10,  9, 39,  7, 22, 40,  4, 35, 10,\n",
      "        15, 12, 13, 34,  4,  2,  5, 25, 37, 17, 15, 14, 15, 11])\n",
      "tensor([26, 18,  9, 17,  1,  7, 23,  1, 35, 11,  7, 10,  1, 13, 10,  9,  1, 10,\n",
      "         0,  2, 13, 10, 13,  2, 18, 13,  4,  2,  8, 16, 17, 18])\n",
      "tensor([39, 15,  2,  9, 15, 17,  2,  8, 33, 33, 23,  1, 11, 28,  9,  4, 14,  3,\n",
      "        22, 17,  9,  3, 26,  2, 16, 17, 18, 12, 29, 11, 18,  1])\n",
      "tensor([ 2, 38, 36, 25,  9,  5, 12,  7, 17,  4, 25,  6, 36, 26,  9,  7, 14,  2,\n",
      "        17, 20, 18, 12, 41,  5, 11, 36,  1, 15, 11, 12, 34, 33])\n",
      "tensor([21,  0,  9, 16, 27,  3, 18, 31,  2, 26, 25, 38, 12,  6, 28, 35,  5, 23,\n",
      "         4,  8, 12, 17, 18,  1, 38, 38,  9, 25,  5,  1,  1, 42])\n",
      "tensor([13, 13,  2, 31, 10, 35, 28,  5, 11, 30, 11,  1, 25, 38, 38, 31, 19, 13,\n",
      "        21, 20,  8, 38, 22, 28, 12, 17, 12, 35, 10, 13, 12,  1])\n",
      "tensor([ 2, 10,  5, 13, 34,  2,  2, 17,  9, 13, 34,  2, 13, 10,  5,  4, 38, 10,\n",
      "         4,  1, 33,  2, 14, 35, 10, 13,  9,  5, 35, 18, 25, 40])\n",
      "tensor([ 3, 13, 31, 22, 38, 39,  2, 25, 23, 11, 23, 12, 17, 36,  1, 38,  2,  8,\n",
      "        18,  4, 10,  7, 38, 14, 10, 38,  9, 14,  1, 25, 14,  1])\n",
      "tensor([ 1, 25,  7, 10,  5, 40, 28, 20,  4,  9,  3,  2, 35,  2, 22,  2,  2,  1,\n",
      "        14,  4,  3, 18, 10,  2, 29, 10, 33, 13, 12, 17, 16, 12])\n",
      "tensor([ 3,  4, 10,  8,  1, 38, 35,  1, 17, 26, 34,  7,  8, 10,  7, 17,  3, 12,\n",
      "        13, 31, 36,  7,  8, 12,  3,  5, 24, 11, 28,  2,  1,  5])\n",
      "tensor([ 5,  9,  1, 13, 13, 13,  7, 31,  1,  2,  7,  1,  2, 12,  2,  4, 11, 24,\n",
      "        38, 10, 27, 26,  6,  4, 11, 23,  4, 35,  7, 15, 31, 23])\n",
      "tensor([11, 25, 18, 27, 41,  1, 23,  8,  4, 15,  7, 25, 12,  9, 20,  1,  1, 11,\n",
      "        11, 13, 13, 15, 35, 25, 11,  8, 36,  2, 10, 12,  2,  3])\n",
      "tensor([34, 16,  8, 10, 12,  9, 11, 11, 35, 30, 40,  4,  2,  1, 18, 17, 35,  0,\n",
      "         2, 12, 12, 12, 14,  8, 31,  1, 26,  7, 10,  5, 31, 13])\n",
      "tensor([ 3, 13, 18,  2, 25, 10,  1,  5,  1,  7, 34, 14,  7,  2, 25, 15,  8, 33,\n",
      "        10, 10,  3, 17, 13, 25, 25,  1, 15,  1, 35, 14,  9, 13])\n",
      "tensor([ 9, 25,  4,  1,  7, 31,  3,  1,  2, 20, 18, 38,  0,  2,  3, 15, 12,  2,\n",
      "         3, 35,  5, 11,  3,  1,  9, 37, 12,  7,  2, 38, 22, 16])\n",
      "tensor([41, 31, 25, 25, 10, 16,  2, 29, 13, 22, 12, 12,  9, 23, 15, 13,  3, 12,\n",
      "        40, 25, 38, 10,  1, 11,  4, 36, 42, 30, 22,  5,  4, 31])\n",
      "tensor([ 4,  9, 28, 13, 13, 16,  7,  5,  3,  9, 15, 14,  9, 19,  5,  5,  1, 13,\n",
      "        28,  8, 14,  6, 10,  1, 23, 13, 36,  2,  0, 28, 40,  2])\n",
      "tensor([12, 15,  5,  4, 13, 35, 12,  4,  5, 11,  1,  2,  9, 18,  7,  1, 18,  2,\n",
      "         3, 12,  8,  1,  4,  4, 15, 14,  8,  2,  1,  8, 40,  5])\n",
      "tensor([35, 22,  5, 35, 12,  1, 35, 12, 10, 38, 11, 38,  2, 36,  8, 11, 16, 42,\n",
      "         0,  1, 16, 12, 11, 15, 25, 20, 17,  1,  4, 40, 15, 25])\n",
      "tensor([35, 12, 11,  2, 18, 24, 25, 18,  7,  9,  5,  8,  2, 32,  8, 10, 12, 13,\n",
      "        16, 12, 14, 38,  4, 38, 18, 38, 12,  7,  9, 38,  2,  2])\n",
      "tensor([ 2, 24,  1, 32,  1,  4, 10,  9, 38, 18,  4,  4, 17, 12,  1, 35, 13,  9,\n",
      "        10, 17, 10,  5, 11,  8,  2, 13, 14, 11, 38, 10, 14, 18])\n",
      "tensor([19, 32,  8,  5,  2, 12, 22,  2, 17,  6,  5, 35, 11,  9,  5, 31, 13, 13,\n",
      "        13, 11, 38, 10, 12,  8,  8,  8,  4, 38, 24, 35, 38, 17])\n",
      "tensor([38, 10, 18, 11, 25,  3, 17,  7, 35,  9, 14,  3, 38, 40, 20, 38,  6, 14,\n",
      "         2,  4,  2, 37, 12,  8,  9, 38, 12,  4, 38,  9, 35,  4])\n",
      "tensor([37, 21, 10,  2, 16, 23,  3,  2, 11, 25, 11,  1,  5,  1, 15, 10,  2,  5,\n",
      "         1, 12,  7,  7,  1, 38, 17, 10, 10, 27, 17,  1,  1, 14])\n",
      "tensor([12,  7,  4, 14, 17, 38,  3,  5, 25, 25, 10, 13,  8,  2, 18, 31, 14, 26,\n",
      "        31, 14, 14,  9, 35,  3, 33,  1, 14, 25,  2,  0, 10, 17])\n",
      "tensor([ 2, 25, 13,  4, 39,  5, 31, 10,  4,  4, 24,  1, 12,  8,  2,  9,  4, 12,\n",
      "        12, 10, 35, 21, 22,  2, 12,  6, 35,  3, 14,  2, 17,  2])\n",
      "tensor([17, 11, 19, 33,  2,  4, 33, 28, 41,  6, 28,  4, 38, 30,  7, 25, 18, 10,\n",
      "        25, 13,  3, 11, 38, 35, 17, 22, 31, 11, 11, 25, 25, 31])\n",
      "tensor([15, 23, 28, 12, 12, 31, 35, 34, 29, 29, 10,  9, 13, 31, 10,  1, 10,  6,\n",
      "        11, 13, 38,  4, 13, 13,  7,  1, 18,  7,  1,  2, 31, 11])\n",
      "tensor([ 0, 11, 28,  0, 25, 18, 30, 23,  1,  1, 25, 13, 10, 37, 15,  5, 11, 15,\n",
      "         9, 11,  5,  2, 13, 30, 25,  9,  5, 13, 20,  3, 18, 10])\n",
      "tensor([10, 14,  1, 25,  3, 10, 13, 35, 18, 18, 10,  4, 26, 28, 15, 17, 17, 14,\n",
      "        35, 12,  7, 38,  1,  1, 41,  8,  5, 20,  1,  6,  2,  2])\n",
      "tensor([23, 11, 12,  1, 13, 35, 15, 25, 10, 38,  5, 28,  9, 34,  1, 38,  9,  8,\n",
      "         4, 16, 27, 23, 10,  0, 39, 12, 10, 41, 25, 33, 15, 33])\n",
      "tensor([25, 27,  7, 13, 11,  1,  1,  7, 28, 17, 12,  7, 12, 31,  5, 38, 13, 24,\n",
      "        13, 14, 10,  1, 25,  5, 22,  1, 15,  8,  1, 25, 13, 12])\n",
      "tensor([28, 41, 38,  0,  7, 33, 38,  5, 28, 35,  4,  4,  2, 31, 16, 12, 12, 12,\n",
      "         4,  2,  9,  4, 20, 31,  7,  4,  9,  9, 35, 13,  9, 38])\n",
      "tensor([12,  7, 32,  9, 11,  7,  5, 13,  7, 12, 11,  1, 25, 12,  4, 17,  6, 38,\n",
      "        38, 12, 31,  6, 22,  4, 20, 15,  1,  8, 40, 26,  9,  3])\n",
      "tensor([40, 13,  8, 34, 17, 36, 12, 40, 38,  4, 31, 35, 31, 18, 13, 25,  1,  1,\n",
      "        17, 31, 16, 10, 12, 42,  9, 39, 35, 13, 10, 13,  4,  4])\n",
      "tensor([25, 34, 12,  2,  8, 29, 31,  4,  1,  8,  4, 30,  0, 15, 13, 25,  2,  4,\n",
      "         2, 12, 28, 11, 35,  4, 10, 38, 31, 12,  7, 16,  6,  1])\n",
      "tensor([21,  5, 13,  2, 13,  2, 24,  5, 34,  9, 17, 26, 25, 24, 12, 17, 27, 35,\n",
      "        29,  8, 31,  5, 15, 22, 10, 28, 25, 12,  8,  9, 11,  1])\n",
      "tensor([17, 29, 38,  2, 36, 30, 30,  1,  8, 13, 38,  1,  5, 29, 11, 18, 11, 10,\n",
      "         4, 15, 12,  7, 21, 38,  2, 13,  7, 12, 10,  1, 35,  1])\n",
      "tensor([ 8, 38, 25, 13, 15, 12,  8, 17, 38,  9, 31, 10, 25,  1, 14, 17, 23, 10,\n",
      "        26, 31,  5, 36, 14,  4,  4,  7, 20, 34,  1, 21, 14,  4])\n",
      "tensor([13,  6, 33, 11, 33, 30,  2,  3, 33,  1, 40,  1, 13, 23, 18, 10, 35,  1,\n",
      "        15, 12, 14,  3, 35, 12,  9, 33, 17, 12, 25, 18,  4, 31])\n",
      "tensor([11,  5, 29, 11,  5, 14, 15,  5, 38, 14,  4, 10, 12,  2, 13, 17, 10,  4,\n",
      "         5,  4,  0,  8, 31,  4, 41, 12, 20, 25, 14,  1, 11, 21])\n",
      "tensor([11, 18, 10,  5, 12, 13, 31, 12,  2, 12, 13, 16,  3,  2, 10,  5, 31, 12,\n",
      "        14, 17, 17, 13, 17, 16, 31, 11, 26, 32, 13,  7, 13,  2])\n",
      "tensor([18,  8,  7,  1,  9, 38,  9, 13, 13,  1,  1,  8,  2,  8, 13, 38,  7, 18,\n",
      "         2, 14, 38,  4, 38, 12, 25,  5, 25, 11, 18,  5, 14, 12])\n",
      "tensor([13,  5, 13,  9, 11, 25,  7, 12, 35, 15,  1,  3, 31, 17, 35,  5,  8, 25,\n",
      "         4, 38, 18, 10, 36, 17, 13,  7, 12,  4,  1,  2,  5, 17])\n",
      "tensor([ 9, 25, 29, 35, 29, 35, 15,  2, 35, 11, 28, 26, 23,  3, 35, 25, 38,  1,\n",
      "        13,  9, 11,  7,  9, 38, 20, 39, 25, 13, 42, 11, 12, 38])\n",
      "tensor([ 7,  3, 10,  8, 35,  5,  5,  5,  9, 35, 31, 24,  0,  0,  5,  9,  1,  1,\n",
      "         4,  7, 25, 12, 33, 14,  2, 15,  9, 12,  1, 11, 33,  4])\n",
      "tensor([ 1, 18, 13, 12, 13,  2, 13, 10, 36, 10, 38,  3, 11, 38, 15, 30, 18, 35,\n",
      "         5,  9, 18,  8, 12, 15,  5,  1, 35,  4, 25,  5,  2, 28])\n",
      "tensor([12,  8,  1,  1,  4,  4,  9, 17,  4, 10, 17, 38,  2,  2, 39,  1, 23, 15,\n",
      "        10,  4,  3, 13,  5,  9,  3, 18,  6,  7, 12, 42, 19, 11])\n",
      "tensor([17,  1, 33,  8, 31, 31,  5,  1, 12, 28,  5, 12,  8, 20, 10, 10,  8,  8,\n",
      "         8,  5,  7, 11, 33, 10,  5, 12, 38, 12,  2,  7,  5,  2])\n",
      "tensor([17,  5, 17, 12, 31, 25, 18,  2, 11,  3, 37,  9, 38,  5, 38,  8, 13, 10,\n",
      "        14, 12, 17, 31, 26, 33, 38, 17, 12,  2,  2, 13,  1, 31])\n",
      "tensor([ 2, 10,  9, 33,  5, 13,  1,  4,  8,  2, 36, 12, 38,  4, 34, 12, 42,  5,\n",
      "         2,  1, 22, 25, 28,  3,  4,  2,  2, 17, 12, 31, 31, 23])\n",
      "tensor([ 0,  1, 35, 40,  2, 10, 10,  7,  9,  4, 34,  5,  7, 30, 12, 13, 35, 28,\n",
      "        12, 35, 10, 12,  8, 25,  5,  1,  5,  1,  2,  2, 12,  3])\n",
      "tensor([ 7, 16,  2,  7, 14, 18, 38, 25,  2, 18,  9, 36,  9, 25,  5,  5,  5,  3,\n",
      "        11, 13,  1, 25, 25,  8, 10, 25,  0, 31,  9,  2,  2,  8])\n",
      "tensor([ 4, 13,  7, 20,  5, 15, 12, 17,  1, 11,  7, 24,  3,  3, 10, 26, 38, 10,\n",
      "        12,  2, 10,  3,  5,  1, 12,  4, 29, 34,  1,  4,  4, 35])\n",
      "tensor([ 4,  5, 13, 33, 37, 37, 38, 33, 38, 12, 31, 11, 19, 38,  4, 12,  8, 24,\n",
      "        12,  2, 13,  7,  7,  1,  9, 38, 25, 20, 33, 35, 25, 24])\n",
      "tensor([ 8,  2, 28, 19,  5, 39,  2,  4, 35, 12,  4, 10, 25,  8,  4,  4, 38,  1,\n",
      "        39,  5, 10,  1,  6,  6, 38, 12, 33, 40,  1, 10,  4, 25])\n",
      "tensor([18,  4,  9, 39, 10,  7,  6,  7,  1, 10, 12, 13,  2,  2, 22,  6, 10, 11,\n",
      "        11, 21, 11, 38,  5,  4, 31, 27, 26, 26, 33,  4, 25,  7])\n",
      "tensor([ 1,  2, 39, 38, 38, 40, 38,  3,  5, 13, 11, 16,  5, 36, 22, 14,  7,  3,\n",
      "         4,  4, 25, 26,  0, 18,  5,  9,  3, 21, 19, 12,  1,  1])\n",
      "tensor([ 7, 14,  7,  7, 13,  4, 13, 18,  4, 38, 12, 12, 13,  2, 17, 17,  1, 26,\n",
      "        19,  7, 18, 14,  4,  1,  7,  8, 20, 10, 16, 28,  5, 17])\n",
      "tensor([25, 12, 38,  3, 28, 13, 31, 36, 13, 15, 38, 25, 18,  4, 11, 25,  2, 38,\n",
      "        19,  8, 10,  7, 15, 31,  4, 39, 25,  1, 25, 17, 38, 16])\n",
      "tensor([10,  1,  7,  5, 17, 10,  9, 25,  4, 17, 13, 18,  5,  5,  5, 10, 25,  7,\n",
      "        10, 11, 11, 42, 13,  2,  4,  4,  2, 22, 35, 17,  4,  7])\n",
      "tensor([ 8, 23,  7, 10,  5, 10, 10,  4,  5,  7, 11,  3, 12, 38, 13,  9, 11, 22,\n",
      "         7,  3,  2, 40, 22, 10, 13, 38,  7, 14, 33,  3,  4, 15])\n",
      "tensor([ 1,  9,  9, 11, 32, 39, 38, 12,  4,  3,  2, 14, 15, 38, 33, 27, 18, 10,\n",
      "        13, 18,  2, 31, 18, 11,  1, 19,  1, 38, 18, 24,  3, 11])\n",
      "tensor([ 1, 33, 40,  7, 25, 31, 29,  7, 35, 10,  5, 12, 16,  8, 13, 17, 10, 14,\n",
      "        23,  8, 17,  9, 25,  1,  1, 38, 12, 31, 10, 31,  5, 10])\n",
      "tensor([ 2, 34, 35, 11, 42, 39,  8,  5, 38,  7, 10,  2,  9, 13, 10, 14, 25, 19,\n",
      "         5,  8, 31, 13,  9, 40, 16, 30, 18,  9,  2, 17, 25,  2])\n",
      "tensor([ 7, 25,  5, 12, 14, 11, 39,  1, 10, 13,  9, 15,  7, 10, 13, 35,  4, 32,\n",
      "        23, 38, 40, 35,  2, 15,  2, 30,  1, 25,  1, 35,  2, 39])\n",
      "tensor([ 2,  3,  4, 26, 12,  4,  3, 35, 26, 14, 18,  1,  5, 13,  1,  2, 33,  9,\n",
      "        29,  1, 38, 18,  3,  3,  4, 17, 12, 26, 28, 33, 42, 25])\n",
      "tensor([13,  9, 18,  6,  2,  3, 13, 11, 38, 18,  3, 12, 32, 13,  2, 35, 13,  5,\n",
      "        10, 27, 35, 17,  1, 29, 35,  2, 25, 14,  8,  2, 14, 38])\n",
      "tensor([ 8, 11,  9, 10,  3, 13, 38, 36, 11, 13, 24, 10, 19, 25, 10, 11, 16, 29,\n",
      "        16, 15,  1, 28, 12,  4, 14, 10, 10, 12,  5,  2, 13,  1])\n",
      "tensor([13,  9,  9,  2, 10, 23, 10, 22, 13,  2,  1,  7,  5, 18, 12,  5,  2, 25,\n",
      "         1, 38, 35, 25, 38,  1, 14,  2, 35, 14, 15, 15,  4,  9])\n",
      "tensor([10,  1,  1, 38, 12, 39, 12, 40, 16, 15, 18, 17, 39,  5, 22,  3,  3, 25,\n",
      "        38,  2, 13, 12, 14, 13, 38,  4, 10, 38,  2, 20,  4, 25])\n",
      "tensor([18,  2,  3, 13, 28,  5, 38,  4, 34,  5, 11, 11, 18, 28, 17,  1, 10, 12,\n",
      "         3, 38, 23, 13,  4, 16, 26,  8,  4, 13, 11, 38, 15, 35])\n",
      "tensor([ 7, 10,  7,  1,  4, 20, 14, 13,  2, 17, 13, 36,  1, 38,  3, 13, 35,  2,\n",
      "        18, 13, 12,  2,  1, 11,  5, 13, 10, 38, 25, 14,  5,  1])\n",
      "tensor([ 9, 17, 40, 12,  4, 31, 40, 26,  2,  6,  1, 11, 26, 35,  9,  3, 14, 11,\n",
      "        38,  5,  4,  2, 38, 18,  4, 38, 38,  3, 12,  1, 20,  5])\n",
      "tensor([40,  2, 38, 41,  1, 12,  5,  3,  4, 15, 13, 38,  1, 38,  3,  2, 10,  1,\n",
      "        38, 13, 18,  1,  5, 23,  1,  4, 31, 12, 12, 25,  5,  4])\n",
      "tensor([23, 25,  7, 38, 17, 12, 10, 13, 15, 23, 18, 25, 34, 20, 11, 20, 23, 12,\n",
      "        13, 36, 18, 11, 33,  7, 17, 10, 38,  2,  2,  6, 13, 14])\n",
      "tensor([ 1, 31, 35, 38, 11, 35, 18, 25, 15,  2,  3, 13,  8, 31,  4, 18, 13, 25,\n",
      "         2, 25, 25,  1,  8, 31, 40, 22, 31,  9, 25, 25, 24,  1])\n",
      "tensor([ 4, 12, 33,  5,  4, 23,  1,  9, 11,  4, 33, 28,  4, 17,  4, 40,  4,  5,\n",
      "         3, 30,  6, 34, 13, 14,  1, 40,  5,  3,  1,  1,  9,  5])\n",
      "tensor([12, 15, 13, 24, 15, 20,  2, 28,  9,  7, 35, 10, 14, 17, 15,  2,  2, 18,\n",
      "        16,  7,  8, 34, 12,  9, 26, 13, 13, 26, 20, 21, 34, 14])\n",
      "tensor([12, 38,  4, 18, 13, 18,  4, 12, 11, 12, 15, 12, 37,  7, 31, 15, 14,  9,\n",
      "        36, 38,  5, 13, 31, 12,  8, 11,  4, 11, 38, 10, 38,  1])\n",
      "tensor([12,  6,  4, 11, 28, 20,  9, 10, 15, 10, 35, 15, 38,  8,  5, 26, 11, 13,\n",
      "        12, 28,  8,  3,  4, 13, 23, 34, 36, 10,  2,  8, 22, 11])\n",
      "tensor([25,  2, 38,  4,  1, 13, 21, 15, 10,  5, 15,  7, 38,  5, 10, 12, 10, 35,\n",
      "        40,  3,  8, 38,  2, 38, 16, 31, 26, 33, 17, 10,  2, 26])\n",
      "tensor([11, 38, 38,  4, 13, 23, 38,  7, 13,  4, 38, 19, 35, 17, 11, 29, 34, 38,\n",
      "        38, 31, 31,  2, 11, 32, 37, 12,  9,  7, 17, 38,  7, 14])\n",
      "tensor([ 2,  1, 11,  1, 29, 11,  5, 14,  9, 38, 10, 25, 34, 17, 10,  1, 13,  9,\n",
      "        11, 39, 18, 25, 33, 13,  7, 12, 25, 10,  8,  5, 38, 12])\n",
      "tensor([32,  8, 13, 38,  7,  7, 26, 15,  4, 18, 33,  2,  1,  2, 11,  1, 17,  1,\n",
      "         1, 12, 10, 10, 13,  4,  2, 36,  8, 12,  7, 11,  5, 15])\n",
      "tensor([28, 40,  1,  7,  4, 17,  9, 17, 40,  7, 31, 10, 18, 13, 25, 17,  9, 38,\n",
      "         7,  3, 29, 12,  4, 10, 25, 13,  5,  3, 37, 19,  7,  3])\n",
      "tensor([14, 35, 13, 17, 15,  1, 13, 38,  3,  5, 11, 18, 20,  5,  8, 18,  5,  7,\n",
      "        12,  5, 38, 14,  2,  4, 17,  2, 37, 40, 31,  7, 18, 13])\n",
      "tensor([16, 13,  7, 11,  5,  7, 31,  2,  4,  8, 11,  8, 25,  9, 14, 12, 10, 16,\n",
      "        17, 38, 25,  6,  5,  1, 35,  2,  2, 11, 12, 11, 17, 12])\n",
      "tensor([33, 38,  2,  4,  8, 28, 12, 29,  1,  9, 17, 38, 35,  9,  2,  2, 20, 12,\n",
      "         5,  2, 25,  2, 33,  7, 35,  4, 35, 12,  6,  7, 10, 42])\n",
      "tensor([13,  5, 31,  3, 38,  1, 16, 11, 23,  4, 10,  4,  5,  8, 24, 31,  3,  4,\n",
      "        12, 21, 29, 26,  4,  1,  6,  5, 10,  4,  9,  7, 25,  4])\n",
      "tensor([21,  1, 12,  4,  3,  2, 39, 38, 33, 33,  1, 37, 36,  5, 24, 13,  7, 10,\n",
      "        19, 23, 34, 18, 12, 14, 38,  5, 42, 13,  5,  3, 10, 37])\n",
      "tensor([ 5, 31, 34,  9,  3, 24, 13, 32, 10, 33, 30,  4, 12, 37, 30, 12, 28, 38,\n",
      "        38,  5, 13,  1, 10, 10, 31, 31,  4, 37,  3, 12,  1,  7])\n",
      "tensor([30, 12, 14, 35, 11, 11,  1,  8, 38,  7, 28, 10, 12,  2, 11, 23,  9, 11,\n",
      "         3,  1, 27,  3, 18,  2,  9,  4, 31, 30, 35,  2, 23, 10])\n",
      "tensor([ 8, 38,  5,  5, 10,  9, 12, 38,  3,  3, 16, 13,  9, 12, 28, 18, 17, 22,\n",
      "         4, 35,  4,  5, 18, 38, 14, 38, 38, 28, 11, 13, 35, 13])\n",
      "tensor([ 5, 38,  2,  7, 11, 18, 11, 11,  1, 13, 10, 14, 16,  4,  1, 11,  4, 10,\n",
      "         4, 38,  4,  2,  1, 10,  5, 33,  1, 18,  7, 15, 15,  9])\n",
      "tensor([ 4, 35, 31, 13,  5, 12,  5, 29,  2,  3, 35, 17,  7,  2, 18, 35,  8, 10,\n",
      "        38, 35,  1, 35,  7,  2, 25,  0,  2,  1,  4, 36, 29,  8])\n",
      "tensor([ 7, 35, 10,  1, 13,  4, 10,  5, 12,  7, 16,  3,  1,  1,  9, 19,  8, 13,\n",
      "        10,  1, 25, 13, 11,  2,  2,  7, 10, 14, 10, 39,  9, 25])\n",
      "tensor([ 3,  6, 17, 13,  2,  3, 17,  2, 40,  1, 10,  5, 32,  8, 12, 42,  4, 35,\n",
      "         0,  1, 30,  1,  2, 29, 13,  3, 36, 15,  4, 23,  5,  5])\n",
      "tensor([ 8,  8,  5,  4,  2, 10, 25,  4, 25, 32, 13, 34, 27, 25, 15, 25, 18,  6,\n",
      "         9,  7,  1, 13, 27,  1,  4, 23, 25, 35, 10,  4,  7, 10])\n",
      "tensor([12, 12, 18, 26, 12, 25, 11, 35, 12, 35,  4, 10,  2,  7, 40, 11, 38, 13,\n",
      "        12, 13, 38,  5, 35, 15, 11, 13, 13, 36,  5, 33,  8, 34])\n",
      "tensor([13,  1,  3, 38, 17,  5,  5, 25,  5, 10, 28, 10,  7,  2, 12,  5,  3,  2,\n",
      "        23, 20,  9,  4, 22,  9,  4, 38,  5,  9, 27,  8,  8, 41])\n",
      "tensor([12, 11,  3,  5,  0, 25,  5, 36,  2, 13, 26, 17,  3, 13,  2, 29, 28, 10,\n",
      "         5,  1, 15, 17, 15,  2, 42,  2, 17, 30, 25, 26, 38, 11])\n",
      "tensor([12,  6, 30, 25, 12, 18,  3, 13,  1, 13, 17, 25, 18,  6, 10, 18, 10,  6,\n",
      "         8,  2, 13, 36, 36, 18,  8, 24, 10, 14, 10,  7, 38,  2])\n",
      "tensor([35,  5,  4, 13,  6, 12,  4, 38,  6,  8, 17,  5, 17,  7, 21,  3, 21, 10,\n",
      "         9,  3, 12, 36, 17,  5, 18, 12, 13, 14,  1,  2, 16,  9])\n",
      "tensor([34,  9, 19, 13, 26,  4,  4, 10, 35, 22,  4,  6, 25,  5,  4, 29, 38, 13,\n",
      "        25, 12, 13, 12,  7,  8, 13, 38,  5, 14, 10, 33, 25, 18])\n",
      "tensor([33, 18,  2, 38, 23,  9,  2,  1,  3, 10,  1, 17, 38,  5,  1,  5, 13,  5,\n",
      "        27,  4,  5, 41,  4,  3, 21, 38, 18, 40, 35, 23, 35, 12])\n",
      "tensor([ 8,  8,  6, 38, 35, 35,  9, 29, 38, 15,  7,  4, 10, 21,  1, 12, 32, 33,\n",
      "         1,  8, 26, 38, 11, 38, 28,  5, 25,  1,  3,  2, 35, 23])\n",
      "tensor([38, 33,  1, 15,  2, 11, 11, 31,  2,  4, 35,  7,  1, 17, 38, 38,  2, 42,\n",
      "        12,  3, 32, 31,  3, 31,  8,  7, 12, 10, 26,  0, 25, 10])\n",
      "tensor([34, 21, 26,  8,  9, 31, 14,  5, 10,  9,  8,  7, 31, 40, 10, 13, 23, 25,\n",
      "         5, 17, 18,  1, 14,  4, 36,  1, 15,  5, 38, 38, 40,  4])\n",
      "tensor([14, 25, 35, 17,  5, 11, 13, 36, 38, 13, 38, 34, 38,  4, 10,  8,  4, 25,\n",
      "        12,  2, 13, 10,  1, 25, 33, 18,  3, 19, 10,  5,  1, 35])\n",
      "tensor([25,  4, 20,  3,  7, 10, 17,  8,  4,  2, 10, 38, 15, 38, 31, 38, 10,  8,\n",
      "        38, 11, 11,  0, 31,  5,  4, 35, 17,  1,  7,  1,  1,  1])\n",
      "tensor([26,  2, 31,  5, 33, 31,  8,  9,  1, 37, 31,  9, 10, 11,  1, 17,  7,  4,\n",
      "         7,  5, 13,  1,  1,  1, 26, 25, 30, 14, 12,  4, 31,  9])\n",
      "tensor([31,  8,  2,  5, 13,  4, 35, 23, 34, 15, 35,  4, 23, 31, 35, 17, 22, 13,\n",
      "         1, 11,  1, 38,  9, 30,  1, 15, 22, 34, 33,  2,  2, 11])\n",
      "tensor([23, 38,  5,  4, 35, 34,  4, 33, 18,  9, 20, 17, 11, 11, 11, 18, 29, 38,\n",
      "        12, 38, 40,  9,  0,  1, 13, 36, 14, 12, 31,  3, 12, 38])\n",
      "tensor([24, 23, 22,  4, 18, 10, 11,  2,  2, 38, 13, 35,  2, 16, 17, 38,  9,  8,\n",
      "        33, 22, 12, 38, 18,  2, 31,  5, 35,  7,  5,  8, 10,  4])\n",
      "tensor([33, 17, 35,  5, 14,  9,  4,  5, 25, 28, 26, 13,  9, 13,  2,  2, 38,  1,\n",
      "         9, 11,  4, 13, 10,  7, 15, 10,  2, 11,  5, 17, 11, 10])\n",
      "tensor([ 3,  9, 10,  7,  5,  4,  5,  8,  1,  8,  6, 30, 33,  2, 35,  5, 10, 12,\n",
      "        12, 22, 11,  5,  5,  9, 42, 33, 10,  8,  9, 12, 38, 22])\n",
      "tensor([ 2, 38, 38,  1, 12,  7, 18,  1, 24, 19, 13, 23, 18, 13,  5,  0, 10, 20,\n",
      "        11, 11, 23, 24, 18, 35, 38,  4, 10, 26, 38, 18,  2,  9])\n",
      "tensor([25, 33, 30, 25, 12, 12,  2,  9,  4, 34, 11,  4, 42, 36,  4, 12,  3,  9,\n",
      "        38, 37, 12, 25, 33, 25, 10,  9, 13, 38, 11,  1,  9, 20])\n",
      "tensor([38, 37, 18, 10, 42,  9, 17, 33, 37, 25, 34, 38,  2, 15, 20,  3, 33, 10,\n",
      "         9,  1, 42, 25, 12,  8, 38,  4, 17, 36, 13, 18, 18, 14])\n",
      "tensor([10,  1,  5, 23, 12, 12, 16,  2, 13, 37, 10, 25,  3,  2,  2, 12, 10,  1,\n",
      "        25, 25, 18,  2,  9, 13, 26, 18, 12, 35, 13, 25,  4, 34])\n",
      "tensor([10,  1, 12, 10, 25,  3, 29,  1,  2, 35,  9,  7, 10, 10, 40,  8, 25, 10,\n",
      "        25, 13,  4, 13, 25, 12,  3,  4, 39, 14, 10, 38,  7, 33])\n",
      "tensor([12, 14, 31, 24,  4,  8, 25, 24, 31,  2,  2,  4, 14,  1,  2, 31, 37, 17,\n",
      "        25,  1,  9, 22, 38, 12, 38,  9, 13,  1,  5,  6, 38,  1])\n",
      "tensor([26,  5, 17, 23,  9,  9, 35,  2,  4,  1, 25, 16,  5,  3, 12,  1,  5,  2,\n",
      "        12, 38, 30,  1,  1, 38,  2,  2, 12, 17, 33,  1, 28,  1])\n",
      "tensor([17,  5,  9, 35, 38,  3,  0,  1, 12,  2, 18, 25, 13, 17,  5, 35,  5, 17,\n",
      "         3, 12, 31,  5, 17, 26, 36,  5,  5, 38, 12,  2, 25, 14])\n",
      "tensor([ 2, 35,  9,  5, 31, 12,  1, 38,  7,  9, 11, 12, 25, 25, 40, 35,  4, 18,\n",
      "        18, 32, 35, 22,  1,  1, 12,  2,  4,  5, 11, 12,  8, 10])\n",
      "tensor([ 5, 23,  3, 10, 33, 26, 13,  1, 31, 36, 17,  7,  2,  5,  2,  5,  2, 13,\n",
      "         7, 33, 28,  2, 13,  4,  1, 10, 18, 42, 38, 25,  5, 11])\n",
      "tensor([ 7,  2,  0, 12, 42,  1,  9, 35, 17, 13, 31,  8, 38,  2, 39,  9, 17, 11,\n",
      "        38,  8, 18,  8, 23, 25, 18, 35, 10, 38,  6,  1, 28, 12])\n",
      "tensor([38, 35, 12, 14, 22, 16, 18,  5,  5, 14, 29, 17,  2,  1,  2, 25, 26,  5,\n",
      "        13, 35, 18, 11,  8, 15,  9,  8, 12,  7,  1, 42,  3, 17])\n",
      "tensor([35,  1, 19, 10, 12,  4, 35, 38, 34,  4,  9,  8, 26,  4,  9, 10, 10, 10,\n",
      "        17, 24, 35,  7, 25, 13,  4,  5, 31, 18, 12,  8,  7,  7])\n",
      "tensor([ 3, 31, 12, 13, 11,  7, 13,  3, 31, 29, 10, 38, 38, 42, 18, 10,  7,  5,\n",
      "        33,  8,  1,  7, 14, 33, 11,  1,  1,  2, 31,  3, 33,  3])\n",
      "tensor([30, 11, 13, 38, 13, 42, 10,  5, 26,  1,  9,  4,  8, 41,  5,  2, 25, 19,\n",
      "        30, 31, 11,  4,  7, 10, 24,  8, 25, 11, 11,  3, 10,  4])\n",
      "tensor([38,  1, 36, 12, 11,  5,  3, 10,  9, 23,  1, 30, 17, 12, 31,  3, 10,  5,\n",
      "         9,  8,  1, 25, 17,  1, 16, 37, 16,  9,  5, 25, 12,  7])\n",
      "tensor([38,  2, 13,  1, 12,  4, 18, 33,  7,  3, 40, 28, 33, 35, 12,  7, 12,  2,\n",
      "         3,  5, 12,  8, 17,  8,  7,  2,  7,  3, 18, 11,  4, 42])\n",
      "tensor([15,  2, 17,  1, 12,  4, 16,  6, 10, 17, 18,  2, 14, 22, 38, 23,  4, 29,\n",
      "         4, 28,  5, 11, 11, 12, 17, 12, 25,  4, 18, 38, 13, 10])\n",
      "tensor([33,  9,  2, 28, 28,  8, 17, 38,  2, 10,  2,  2,  8,  7,  7, 14,  3, 32,\n",
      "        11, 16,  9, 15,  2,  2,  4, 11, 38, 11, 13, 18, 11, 22])\n",
      "tensor([10,  5, 18, 18, 38, 12,  1, 13, 12,  9,  1, 41, 38, 11, 30,  1, 33,  4,\n",
      "         3, 15, 22,  4, 38, 30, 36,  2, 42,  5,  5, 31, 18,  5])\n",
      "tensor([ 6, 12,  1, 40,  2,  8, 34, 36, 10, 12, 14, 42,  1, 18,  5, 12,  4, 34,\n",
      "        26,  1, 25, 12, 28,  8,  5, 35, 25,  5,  1, 32, 14, 36])\n",
      "tensor([ 2,  9, 12,  7,  2,  3, 11, 35, 41, 42, 18, 35, 10,  1, 14, 38,  7, 17,\n",
      "         1, 35, 23,  8,  3,  3, 32, 38,  1,  5, 12, 13,  8,  8])\n",
      "tensor([ 4, 22,  8, 26, 28,  4,  1, 38,  9,  9,  3, 10, 29, 33,  7, 16,  9,  2,\n",
      "        22, 31, 39,  9, 15, 35,  5, 38,  2, 35, 38, 11,  2, 23])\n",
      "tensor([22, 38,  2,  8, 12,  5, 14, 22,  2, 13, 38,  4, 31,  2, 18, 31, 12,  5,\n",
      "        33,  5,  3, 38, 13,  6, 13, 14, 13, 35,  6, 31, 11, 35])\n",
      "tensor([15, 10,  1, 19, 17,  6,  7, 32, 30, 10, 25,  9, 36, 13, 21, 10,  2, 17,\n",
      "        18, 37, 25,  5, 28,  2, 17, 28, 12,  7,  1,  8, 35,  3])\n",
      "tensor([22,  2,  8, 16, 31,  1, 28, 12, 17, 13, 40, 11,  8,  2,  8, 30,  3,  8,\n",
      "        22, 12, 25, 25,  6,  8, 30,  2,  9,  7, 25,  7, 42, 18])\n",
      "tensor([ 4, 14, 14,  5,  9, 31, 15,  7,  8, 14,  9, 20,  3, 12,  3, 38, 13,  5,\n",
      "        16, 10, 33,  7, 12,  1, 31, 33,  8,  1,  9, 21, 13, 35])\n",
      "tensor([ 8, 33, 14,  2, 10,  1,  5,  1, 13, 18, 37,  4,  6,  3,  8, 38, 42, 29,\n",
      "         5,  2, 18, 35,  5, 23, 38,  8, 38, 13, 38,  1, 36, 35])\n",
      "tensor([18, 23, 11, 10, 25, 28,  5, 29, 31, 14,  1, 38,  3,  1, 14, 11, 25, 38,\n",
      "         8, 12, 39, 18, 17,  4,  4,  1,  1,  4, 12, 25, 12,  5])\n",
      "tensor([12,  1, 12, 12, 38, 11,  4, 30,  9,  4, 17, 25,  4, 16, 18, 13, 23, 18,\n",
      "         1, 12, 12, 10,  2, 42, 13,  4, 22,  2,  3, 13, 19, 16])\n",
      "tensor([ 3,  4, 28,  5, 31, 13, 25, 35,  1, 18, 39, 38, 36, 20, 38, 38,  3, 13,\n",
      "        28, 17, 10, 11, 38,  7, 26, 33, 10, 28,  2,  3,  3, 13])\n",
      "tensor([ 2, 12, 31, 38,  2, 34,  9,  1,  8, 31,  3, 31, 33, 12,  1,  6, 35, 11,\n",
      "         4,  2, 38, 34, 12, 12, 40,  9, 10,  4, 12, 25, 31, 25])\n",
      "tensor([ 2, 13, 16,  3, 31, 33, 12, 12, 15,  4, 17,  8, 38, 33, 31, 38, 13, 13,\n",
      "         2, 31, 10,  2,  5,  4,  4, 38, 17,  7, 21, 31, 12,  8])\n",
      "tensor([25,  4, 13,  7,  1, 38, 38,  1,  2, 12,  7,  2, 25, 30, 38, 40, 12, 29,\n",
      "         8,  9, 30,  5, 12, 38, 10,  1, 35,  4, 16,  4, 25,  7])\n",
      "tensor([ 4, 42, 25, 20, 12, 11,  9,  5, 27, 38,  4,  5,  2, 40,  4,  1,  9,  3,\n",
      "         5,  1, 12, 11,  2, 10,  1, 20,  1, 28, 13, 20, 25, 12])\n",
      "tensor([ 5, 18,  8, 36, 11,  7,  3, 10, 10,  2,  2,  7,  8, 13,  2, 13, 28,  9,\n",
      "         4, 39, 10, 13, 12, 18, 16, 38,  9,  8, 13, 11,  3, 28])\n",
      "tensor([40,  8,  7, 18,  2, 17,  8, 16,  6, 33, 31,  9, 34, 17, 38,  9, 12,  2,\n",
      "        35,  4,  8, 18, 37,  8, 13, 12, 13, 11, 13, 12, 38, 12])\n",
      "tensor([ 8, 31,  7, 30,  5,  7, 31,  9, 10, 38,  8, 28, 10,  5,  5, 25, 24, 14,\n",
      "        26, 28, 35,  4,  1,  4,  7, 39, 13,  5, 35,  3,  2, 31])\n",
      "tensor([25,  3,  5, 10, 35, 42,  7, 25, 40,  8, 38,  5,  2, 12, 38,  1, 13, 12,\n",
      "        33, 38,  4,  5,  5, 11, 25, 10,  7,  4, 35,  2,  8,  4])\n",
      "tensor([ 1, 34, 14, 13, 18, 37, 13,  5, 12, 10, 17, 17, 30, 20, 22, 10, 14, 38,\n",
      "        12, 12, 25, 12, 13, 35,  3, 25,  5,  1, 17,  4,  4, 13])\n",
      "tensor([26,  3,  5, 23,  1, 34, 21, 18, 12, 12,  4,  2,  1, 22, 33, 31, 11, 16,\n",
      "        14, 32, 16, 37,  5, 35,  5, 15, 26, 25,  5, 10, 25, 40])\n",
      "tensor([ 2,  5, 33, 10, 13,  1, 15, 38,  7,  1, 13, 35, 35, 42, 11,  1, 35, 29,\n",
      "        12, 37, 13,  8,  7,  5,  2, 14,  3, 38, 13, 15, 25,  7])\n",
      "tensor([ 3, 18,  9, 28,  3, 23,  2,  4,  9,  3, 34,  2, 10, 25,  1, 38, 38, 24,\n",
      "         5, 19,  3, 35,  7, 11, 11, 11,  3, 23, 10, 18,  4,  1])\n",
      "tensor([32,  5,  4, 38,  7, 38, 20, 18, 16, 21, 23, 13, 25, 21,  4, 10,  7,  2,\n",
      "        12, 40, 12, 34,  8,  9, 38, 18, 13, 38,  3, 17, 35, 40])\n",
      "tensor([ 7,  9,  9,  9, 21, 38, 24, 10,  2, 12, 27, 31, 25, 36, 11, 24,  8, 35,\n",
      "         9,  5,  1, 38, 13, 18, 39, 38,  0, 29, 18, 10, 13, 30])\n",
      "tensor([17, 16,  9, 35, 22, 13, 13, 13, 13, 13,  2, 13, 25,  3, 35,  2,  2,  9,\n",
      "         8, 38, 35,  7,  9,  9,  2,  1, 33,  2, 17,  5,  5,  3])\n",
      "tensor([13, 34, 13, 35, 28, 10, 11,  2, 32, 12,  2, 13, 11, 35,  4, 12, 17,  2,\n",
      "         1,  1, 28,  4, 21, 17,  3,  1,  2, 18, 10, 12, 30,  1])\n",
      "tensor([ 7,  2, 25, 40,  8, 27,  4, 41,  7,  3, 15,  9,  1,  7, 32, 14, 12,  9,\n",
      "        12, 34, 12,  2, 35, 10,  7, 26, 12,  8,  3, 11,  7, 38])\n",
      "tensor([ 5,  4, 33,  1, 29,  4, 25, 25, 37, 12, 10, 15, 38, 11,  5, 18,  2, 13,\n",
      "        35, 26, 13, 38, 13,  2, 19, 12, 38, 25, 38,  6,  5,  5])\n",
      "tensor([ 9, 34, 29, 13,  3, 10,  5, 40,  4,  5, 13, 29, 12, 42,  1,  7,  5,  3,\n",
      "        19,  1,  5,  2,  9, 38, 12, 33,  2, 22,  1,  1,  2, 35])\n",
      "tensor([ 4, 17, 31, 18, 31, 10, 10, 38,  1,  9, 35, 31, 28, 16, 17,  8, 23,  5,\n",
      "         2,  7, 13, 13,  7, 13, 38,  8, 35,  9,  9, 13, 41, 35])\n",
      "tensor([ 2, 12, 33, 18,  4,  1, 12,  1,  5, 11, 38,  7, 18, 14,  2,  8, 38,  4,\n",
      "         9, 11, 12, 12,  3, 35,  4,  3, 28, 31,  1,  4, 26,  2])\n",
      "tensor([38,  2, 14, 13, 26,  4, 13, 40, 11, 11,  1, 21, 18, 25, 38,  6, 34, 33,\n",
      "        12, 16, 15, 18,  3,  1, 10,  5, 12,  1,  4, 11,  9,  2])\n",
      "tensor([34,  3, 29,  6, 35, 12, 25, 35, 15, 38,  4, 12, 37,  4, 13, 38,  2, 37,\n",
      "        10, 11, 31,  6, 38, 25, 40,  7, 17, 35, 21, 10,  9, 38])\n",
      "tensor([12, 38,  2, 37,  9, 33, 31,  1,  4, 20, 31, 13, 25, 23, 38,  1, 28,  2,\n",
      "        11,  1, 33, 18,  9, 20, 25, 25,  2,  9, 10,  8, 39, 38])\n",
      "tensor([ 9,  4,  2,  8, 25,  5,  3, 13,  4,  3, 18, 25, 13, 12, 19, 13, 25,  4,\n",
      "        12, 39,  5,  5,  5,  3,  5,  8, 23,  4, 12, 28,  4,  9])\n",
      "tensor([12, 13, 13, 17,  5,  4, 11, 39, 37, 13,  3,  5, 24, 10, 12,  6, 38, 17,\n",
      "        12, 31,  1, 11, 15, 15,  4,  7, 13, 13, 34,  7, 11, 21])\n",
      "tensor([14, 30, 38,  4, 20,  4,  9,  1, 41, 10, 34,  2, 12,  1, 20,  2,  4, 25,\n",
      "         9, 16,  3, 26,  1,  5,  8,  7,  9, 14, 14, 14,  7,  4])\n",
      "tensor([23, 28, 11, 25, 33, 11,  6,  6, 11, 12,  4, 13, 16,  7,  2, 10, 13, 10,\n",
      "         4, 20, 38, 10, 15, 10,  9, 37, 18, 38, 38, 13, 20, 13])\n",
      "tensor([17,  1, 17,  7, 11,  2,  7, 18, 36, 18,  9,  2,  7, 39,  7, 25,  5, 25,\n",
      "        15,  4, 35, 10,  1, 12,  1, 12, 13,  5,  8, 18, 10, 35])\n",
      "tensor([39,  5, 10, 13, 14,  1,  2, 12,  3, 38,  1, 38, 35,  1, 12,  2, 23, 23,\n",
      "         2, 28,  8,  4, 35,  8,  1, 13, 10, 17, 17, 14, 27,  2])\n",
      "tensor([10, 35, 38, 38, 13, 31,  4,  7, 11, 11, 14, 18, 31, 22, 18, 10,  4, 11,\n",
      "        13, 38, 10,  8, 13, 24,  5,  4,  3, 23, 17,  1,  8, 14])\n",
      "tensor([ 2, 13, 12,  2, 13, 31, 38, 23, 28, 35,  8, 16, 31,  5, 12,  1, 12, 34,\n",
      "        15,  7, 14, 13, 15, 12,  2,  4,  1, 17, 13, 12,  1,  9])\n",
      "tensor([29,  5,  9, 38,  5,  9,  8, 38, 28,  4, 12,  2,  1, 13, 13,  8,  1, 31,\n",
      "         2,  8, 19,  2, 12, 12, 11, 12, 17, 17, 36, 12, 12, 18])\n",
      "tensor([14, 23,  9, 13,  5, 26,  6,  3, 13, 13, 31,  3, 41, 23, 10,  1, 25, 38,\n",
      "         8,  5, 25, 18,  8,  5, 15, 10,  9, 11, 42, 22, 18, 33])\n",
      "tensor([ 5, 30,  5,  5, 16, 28, 17, 41, 38, 12,  2, 12,  9, 13, 38, 17,  4, 25,\n",
      "        30, 13,  1, 12, 38,  9, 12, 33, 42, 38,  2,  2, 16, 32])\n",
      "tensor([ 5, 15, 22, 35, 27, 10,  1, 17,  4,  8, 24, 33, 18, 18, 25, 31,  9, 15,\n",
      "        38,  9,  2, 15, 38, 10, 10, 23,  9, 38, 34, 38, 16,  4])\n",
      "tensor([15, 32,  5, 13,  4, 27,  5,  4,  9, 38,  1, 35,  2,  1, 34, 12, 42,  7,\n",
      "        13,  2,  7,  5, 35,  2, 25,  7, 13, 13, 13, 38, 29, 25])\n",
      "tensor([ 8, 17,  5,  5, 12, 15, 15, 11, 40,  9, 11,  8, 15,  1,  4,  6, 35, 26,\n",
      "        28, 18,  2, 42,  8,  3, 30, 13, 30, 17,  3, 13,  2, 38])\n",
      "tensor([41, 34,  4, 12, 25, 26, 18,  5, 13, 29,  1, 11, 38, 14, 23, 10, 29, 18,\n",
      "         8, 13, 33, 10, 17,  4, 26, 13,  6, 25,  9, 39, 23, 38])\n",
      "tensor([11, 36, 25, 35, 12, 39, 15,  3,  3, 25, 25, 38, 10, 14, 13, 23,  2, 12,\n",
      "        12,  4, 14,  2,  2,  4, 25, 31, 32,  4,  4, 10, 41, 24])\n",
      "tensor([15, 10,  9, 31, 31, 10, 36, 35,  2, 36, 11,  7,  1, 31, 18, 12, 38, 38,\n",
      "         3,  7,  9, 38,  5,  2, 13, 13, 17,  4,  7, 10, 18, 13])\n",
      "tensor([ 3,  2, 31, 33, 38, 21,  2,  1, 15,  2, 42, 10, 13, 33, 38, 25, 26,  5,\n",
      "         5,  5,  7, 25,  9, 13, 33, 34,  1,  5, 12, 31,  4, 13])\n",
      "tensor([42,  3, 38,  2,  7, 14, 19,  2,  6, 12,  2, 25, 20, 11, 23, 12,  4,  3,\n",
      "         4, 23, 36, 38,  2, 33, 21,  5,  8, 18, 10,  1, 38, 19])\n",
      "tensor([ 9, 18, 14, 16, 17, 12, 25, 35, 10,  5, 11, 14,  4, 14, 23, 10, 16, 38,\n",
      "         5,  3, 11,  1,  1, 38,  9, 11, 38, 26, 16,  2,  3,  3])\n",
      "tensor([32,  9, 11,  7,  1,  5,  8, 23, 39, 12,  1,  4, 28,  1,  5, 23,  1, 33,\n",
      "         3,  9,  4,  5, 31, 38, 22, 10,  3, 10,  2,  5,  4, 37])\n",
      "tensor([20, 35,  9, 15, 15, 12, 34, 13, 11, 12, 26, 38, 25,  2, 12, 21,  7, 24,\n",
      "        33,  1,  5, 10, 23,  5,  4,  6,  2, 25,  3,  5,  1, 18])\n",
      "tensor([10, 29, 12,  4, 35, 39, 33, 24,  3,  4,  2,  3,  2, 10,  1, 22,  8, 10,\n",
      "        11, 15, 25,  4,  7, 11,  3, 38, 25,  8,  8,  4, 36,  5])\n",
      "tensor([10,  4, 13, 35, 13, 17, 25, 28,  3, 10, 13, 12,  1,  6, 13, 18, 24,  4,\n",
      "         2,  3, 30, 32,  1,  8, 38, 14, 12, 24, 25,  1,  4, 38])\n",
      "tensor([10, 12, 12, 22, 13, 11, 11, 32, 32, 40,  1, 18, 37, 12, 13, 31, 35, 38,\n",
      "        30, 13,  5, 38,  9,  5,  8, 26, 10, 10, 17,  2, 24, 33])\n",
      "tensor([ 9, 11,  4,  1, 10,  2, 11, 12, 25, 38, 10, 10, 38, 10, 13, 13,  5, 32,\n",
      "        12,  1, 35, 10,  3, 25, 13,  5,  7,  9, 35, 23,  2,  5])\n",
      "tensor([24, 37,  5, 12, 38,  9,  1, 13, 35, 25, 10, 17,  9, 10, 15, 36, 12, 42,\n",
      "         1,  4,  7,  2,  2, 22, 10,  4,  0,  7,  2, 29, 30, 18])\n",
      "tensor([39, 31, 13,  8,  5, 18, 27, 18, 23, 12,  3, 35,  5, 25,  8,  4, 14,  7,\n",
      "         2, 21,  8,  9, 12,  1,  2,  2, 40, 18, 13, 18,  7, 11])\n",
      "tensor([10, 15, 10, 12,  2, 35, 13, 38, 22, 28,  8, 11, 10, 13,  4,  6, 25,  1,\n",
      "        18, 18, 25,  8, 34, 18, 13, 11,  5, 31, 11, 28, 37,  4])\n",
      "tensor([ 8, 12,  5,  2, 14, 13, 17,  8,  1,  3, 18,  4,  3,  8, 28,  1, 36, 34,\n",
      "        25,  7,  2,  9,  3, 30,  2, 13,  7, 23, 38,  2, 17,  1])\n",
      "tensor([14, 36, 13,  3,  1, 38, 41, 38,  3, 11, 15, 35, 16, 12, 13, 25, 14,  1,\n",
      "         2,  1, 33,  1,  8,  4, 35,  6,  6, 18, 33, 38, 10, 14])\n",
      "tensor([ 4, 12,  9, 33, 34, 35, 28, 18, 14, 13, 34, 13, 11, 20,  8,  5,  2,  8,\n",
      "         5, 12,  7, 33,  2, 10, 36, 26, 28, 13, 31, 38,  2, 22])\n",
      "tensor([29, 25,  6, 11, 11, 18, 10,  6, 38, 22, 27, 10,  1, 23, 38,  7,  8, 13,\n",
      "         5, 10, 34,  1, 12, 10,  2, 31, 23,  2,  9, 35,  1,  4])\n",
      "tensor([ 5, 17, 38, 24,  3, 10,  2,  6, 12, 12, 39, 18, 25, 13,  7,  1, 13, 28,\n",
      "        23,  3, 10, 38, 41, 11, 12,  2,  2, 33, 10, 38, 38, 16])\n",
      "tensor([ 1, 23,  5,  9, 17,  8, 25, 26, 21, 10, 15,  4,  3, 25,  8, 13, 35, 16,\n",
      "        25,  9, 19, 42, 20,  8, 15, 27, 15,  4,  7, 17, 11, 38])\n",
      "tensor([38,  1, 11,  3,  1, 11,  1, 38, 29,  1, 26,  4,  1,  1,  4,  1, 17,  4,\n",
      "         1,  1, 10, 35,  5,  3, 27,  9,  1, 16, 14, 12, 35, 38])\n",
      "tensor([20, 35,  1,  3, 10,  5, 24, 32, 13,  5, 27, 27, 19, 11, 29,  9, 10, 27,\n",
      "         4,  5, 35, 15, 12,  8,  2,  5, 38,  5,  2,  9, 10, 14])\n",
      "tensor([12,  4, 26, 35, 10,  4,  5, 14, 13, 10,  9, 18,  4, 13,  3, 15,  9, 14,\n",
      "         2,  4, 17, 33,  7,  6,  3, 42,  4,  1, 26, 38,  2, 11])\n",
      "tensor([13, 16,  2, 16, 25,  4, 12, 17, 31, 38, 13, 20, 13, 12,  1, 10, 35, 38,\n",
      "        35, 11, 10, 26, 38,  7,  5, 18, 12, 28,  1, 14, 26, 38])\n",
      "tensor([10,  9,  1, 38, 13, 22,  5,  4,  5,  5, 14, 14,  2, 13, 42,  5,  6,  3,\n",
      "        38,  5,  8, 35, 15, 13,  3,  5, 10, 22,  2, 35,  9, 11])\n",
      "tensor([14, 25, 35,  4, 22, 25,  5, 12,  2, 10, 17, 13, 13,  1, 14,  3, 38,  4,\n",
      "         1,  4, 13,  7,  1,  2, 19,  4, 10,  4, 30,  4,  9,  2])\n",
      "tensor([ 7,  7, 10, 11,  5,  8, 33, 18, 13,  7,  4,  2,  3, 38, 28,  3, 12, 12,\n",
      "        38, 16, 38, 38, 13,  3, 33,  7, 34, 11,  5, 18, 18, 11])\n",
      "tensor([ 4,  9,  5, 38, 28,  8,  2, 38, 13, 39,  8,  3,  8, 10, 14, 18,  4,  3,\n",
      "        15, 36, 38,  2, 13, 34, 11, 25, 13,  2,  7,  5,  3, 13])\n",
      "tensor([ 4,  7, 25,  4,  8, 10, 31,  9,  1, 26, 12, 29, 31,  2,  7, 12, 25,  9,\n",
      "        18, 16, 11, 18,  4,  2,  1, 10, 13, 13,  1,  9, 37, 20])\n",
      "tensor([12, 19, 12, 38,  2, 11,  2, 33, 13, 34, 14, 13, 25, 38,  5,  4, 24, 38,\n",
      "         6, 35, 11,  1,  2, 15,  1, 38, 25, 13, 10, 25, 26, 13])\n",
      "tensor([12, 11,  9,  9, 39,  8, 31, 13,  2, 17, 19, 12, 23, 17,  2, 14, 10, 28,\n",
      "        16, 11, 36,  8,  4, 10, 37, 32, 25,  8,  2,  3, 29, 32])\n",
      "tensor([25, 17,  2, 26,  2,  7,  9,  8, 33,  4,  9, 14, 42, 12,  3, 38,  4, 31,\n",
      "        11,  9,  4, 26, 17, 38, 33, 23, 26,  3, 12, 13,  4, 31])\n",
      "tensor([12, 33, 13,  7, 33, 10, 14,  9, 13,  2,  7, 24,  5,  2,  4,  9,  4, 13,\n",
      "        35, 35, 13, 26, 13,  1, 13, 15, 25,  8,  6, 13, 32, 10])\n",
      "tensor([ 7, 38,  7, 14, 38,  1, 22, 26,  2,  1, 12,  8, 12,  3, 12, 17, 19, 42,\n",
      "         9, 10,  2,  6,  9,  2,  5,  2,  5,  3, 10,  9,  8, 31])\n",
      "tensor([12, 10, 38, 38,  8,  5,  3,  8,  4, 20,  5,  2, 12, 35, 31,  3, 38, 14,\n",
      "        17,  9, 13,  1, 11, 40, 13, 18,  9,  3, 13, 35,  4, 13])\n",
      "tensor([35, 15,  2, 24, 13,  8,  5, 38,  4, 17, 38,  1,  2, 28, 25,  5, 27, 12,\n",
      "        20, 38, 25, 13, 12,  4, 33, 23, 11, 13,  1,  6, 10,  6])\n",
      "tensor([23, 12, 38, 11,  1, 38, 18,  4, 25,  2, 38, 13, 25,  5,  1,  9,  4,  8,\n",
      "        25,  2, 11, 33, 14, 13,  9,  9, 17, 12,  9,  8, 11,  5])\n",
      "tensor([ 4,  0,  4, 10, 13, 28, 18, 10, 39,  5,  3, 22, 35, 16, 26, 35,  7, 18,\n",
      "         3, 39, 16, 35, 25,  4,  9,  5, 11,  1, 11, 36, 42,  1])\n",
      "tensor([12,  4, 26,  3, 38, 34,  7,  3,  2, 11, 25, 25,  9,  3, 35,  3, 26,  5,\n",
      "         2, 38, 27, 14, 17, 12, 10,  7, 35,  3, 18, 25, 18, 10])\n",
      "tensor([ 2, 11, 11,  4, 38, 38, 13, 20,  8, 26, 10, 12, 11, 13,  1,  4, 13,  1,\n",
      "        12, 33,  1, 31, 35,  3,  7, 12, 10,  2, 31, 10, 28,  9])\n",
      "tensor([25, 36, 15, 38,  3, 17, 10, 12, 15, 13, 17, 29, 22, 12,  4, 17, 17,  8,\n",
      "         2, 10, 16, 33, 22, 35,  2, 40, 14, 11,  1, 18, 35, 22])\n",
      "tensor([24, 18, 15,  3,  5,  4, 38, 12, 11,  3, 10, 19, 24,  9, 11, 12,  3,  5,\n",
      "         6,  3, 33, 13, 12,  4, 33,  5, 15, 18, 12, 25, 40,  7])\n",
      "tensor([13,  1, 32, 10, 10, 17, 24, 14,  4, 10,  4, 11, 13,  8, 15, 30, 10, 14,\n",
      "         1, 11,  9,  2,  4,  5,  2, 38, 12,  8,  2, 10, 23, 11])\n",
      "tensor([17,  9, 13, 23,  7, 25,  4,  7, 35,  2, 41, 35, 22, 10, 13, 38, 17,  8,\n",
      "        38,  4, 15,  7,  9, 22, 30, 12, 38,  7,  4, 38, 13, 13])\n",
      "tensor([10, 38, 33,  1, 21, 38,  4,  9,  8, 37, 12, 42, 13, 25,  9, 10,  2,  5,\n",
      "        16, 12,  9, 33, 18, 10,  1, 30, 10,  8,  5,  1,  4,  5])\n",
      "tensor([ 1,  8,  2,  5,  5, 14,  4, 35, 15,  9, 33, 12, 36,  7, 25, 42, 18,  9,\n",
      "         7,  7, 12, 26, 33, 15, 26,  8, 18, 13, 18,  4,  2, 10])\n",
      "tensor([ 5, 11,  4,  8,  2, 33,  9, 33, 33,  9,  8,  4,  1, 10, 15, 11, 23,  4,\n",
      "        38, 12,  7,  3,  1, 12, 14,  4, 17, 24, 10,  1, 13, 11])\n",
      "tensor([ 9,  2, 14, 17,  9, 25, 38, 17, 15, 38, 13, 10,  4,  4, 25, 33,  3, 11,\n",
      "        11,  5,  4, 33, 18, 17, 17, 20, 13,  5, 23,  4, 12,  4])\n",
      "tensor([ 7,  4, 10,  2,  7,  4,  0, 25,  5,  1, 17, 10,  4,  6, 37,  4, 32, 32,\n",
      "        35, 41, 13, 38, 35, 25,  2, 21, 38,  8,  9,  2, 12, 25])\n",
      "tensor([14, 28,  9, 14,  1, 25, 10, 42, 35,  8, 25, 36,  4, 25,  4, 31, 11,  3,\n",
      "        31,  2,  9, 23,  2,  2,  9, 12,  7, 10, 10, 29, 10,  4])\n",
      "tensor([ 8, 13, 12,  4,  8, 18, 12,  2, 16,  1,  4, 18,  4, 18, 13,  5, 25, 25,\n",
      "         5, 25, 39, 38,  7, 14, 28, 23,  8, 12, 10,  2, 10, 13])\n",
      "tensor([10,  3,  3,  1, 13,  4, 18,  2,  9,  3, 39, 21,  3, 10, 12, 10, 28,  1,\n",
      "         9,  4,  7, 15, 32, 35, 13,  2, 16,  3, 27,  8, 21, 29])\n",
      "tensor([20, 38, 38,  9, 38, 11, 10, 25,  4, 21, 15, 14,  4, 11,  4, 13, 17, 18,\n",
      "        26, 26,  2, 26,  9,  1,  4, 25, 18,  3, 22, 11, 12, 31])\n",
      "tensor([13,  4, 36, 23,  1,  2, 11,  8,  8,  1, 11, 10, 22, 12,  4, 40,  2, 31,\n",
      "        35, 25, 38, 17, 39, 42, 28,  4, 20, 11, 10, 10,  2, 31])\n",
      "tensor([25, 22, 38,  7, 25, 10, 22,  4,  2, 12, 17,  1, 25,  9, 12,  3,  8, 38,\n",
      "        33, 38, 21, 34, 17, 18, 11,  4,  9,  2,  3, 14, 17,  1])\n",
      "tensor([24,  9,  9, 11,  8,  3,  2, 18, 17, 28,  9, 28, 12, 14, 13,  8, 26,  1,\n",
      "         1, 17,  4, 18, 13,  3, 34, 12,  2, 22,  1, 18, 16, 25])\n",
      "tensor([ 1, 35, 25, 30, 14, 35, 26,  2, 20, 38,  5,  7, 14, 25, 28,  2,  5,  1,\n",
      "        26,  9,  5,  1, 13,  4,  3, 11, 25, 31, 13, 11, 25, 38])\n",
      "tensor([ 5, 12,  2, 20, 18,  8, 12, 18, 12,  2,  9, 25, 36,  9, 10,  8,  2,  4,\n",
      "        42,  1,  4,  5, 29,  4,  2, 42, 18, 13, 25, 12, 12, 12])\n",
      "tensor([ 2, 39,  4, 10, 12,  2,  3, 10, 38, 35,  2, 33, 28,  1,  6, 42, 25,  2,\n",
      "         2, 15,  8, 36, 26,  2,  3, 32,  6,  7, 14,  1,  1, 13])\n",
      "tensor([ 4,  1,  2, 15, 17,  2, 10, 25,  5, 31,  4, 11,  2,  5,  2, 13, 13, 10,\n",
      "        38,  1, 18,  9, 35, 38, 35, 13, 18, 21, 18, 22, 22,  8])\n",
      "tensor([38, 33, 14, 28,  8, 38, 13,  7,  9,  9, 35, 11, 13, 35,  3, 33, 38,  8,\n",
      "        38, 12,  9,  2, 33,  3, 13,  5, 35, 23, 12,  4,  1,  5])\n",
      "tensor([ 5, 31, 11,  9,  8, 17,  1, 18, 25, 30,  7, 13,  2,  4,  5,  3, 22, 16,\n",
      "        29, 40,  2, 39,  3,  1, 11,  1,  3, 38, 18,  5, 13, 17])\n",
      "tensor([38,  5,  2, 10, 11, 12,  8, 13, 25,  3,  1, 38, 13, 11, 26, 11,  3, 11,\n",
      "        27,  9,  2, 26, 35,  1,  1,  9, 10, 36,  9,  2, 11, 31])\n",
      "tensor([ 4,  3, 13, 13, 13,  2,  5, 10, 35,  9,  4,  7, 41, 25, 17,  4, 15,  3,\n",
      "        16, 13,  4, 31,  3, 17,  8, 17, 38, 14, 25, 13, 41,  1])\n",
      "tensor([ 1, 11, 15,  3, 36, 10, 10, 16,  2, 24, 23,  2, 17,  3,  4, 15,  2,  7,\n",
      "         1, 12,  4, 11, 13,  4, 22,  8,  1,  2, 38, 13, 31,  9])\n",
      "tensor([ 8, 25,  2, 18, 11, 11, 17, 13, 17,  2, 14,  5, 31, 36,  3, 10, 13, 23,\n",
      "         4, 38, 31,  3,  8,  2, 24, 12, 12, 38, 13, 14, 10,  2])\n",
      "tensor([14, 17, 38,  4, 37, 35,  2, 23,  7,  1, 26, 38,  3, 17, 15,  3,  6, 13,\n",
      "         3, 20, 17, 13,  4, 24,  7,  8, 19,  9,  5,  4,  4,  7])\n",
      "tensor([17, 38, 13, 14, 30, 12,  9,  8, 28,  8, 38, 11, 33, 38, 11,  8, 14, 17,\n",
      "        35,  3, 40, 25,  7,  7, 13,  1, 25, 38, 25,  9,  5, 11])\n",
      "tensor([12,  1, 25,  1, 31, 19,  3, 16, 10, 12, 11,  7,  2,  2,  4, 35,  5, 22,\n",
      "         7,  9, 16,  1,  8, 38,  5,  1,  3, 38, 23,  1, 32,  9])\n",
      "tensor([12, 13, 30,  7,  2,  4,  7, 26,  4,  1,  8, 17,  6, 15, 37, 12,  8, 20,\n",
      "        12, 16, 25, 14,  5,  1, 13, 38,  1, 35, 13, 11, 13,  2])\n",
      "tensor([ 4, 38, 25, 25,  4, 23, 10,  3,  3,  5, 42, 37,  2, 10, 13, 23, 35, 38,\n",
      "         3, 10, 22,  2, 18, 36,  5, 15, 16, 31, 31, 16, 35,  9])\n",
      "tensor([35, 38,  7, 17, 12,  4,  4,  1, 11,  8, 32, 38, 25, 17, 33, 10, 17, 10,\n",
      "         4,  3,  4,  5, 17,  4,  1,  2, 11,  7,  1,  2,  2, 36])\n",
      "tensor([33,  8, 12, 25, 34, 28, 16, 12, 42, 18,  9, 12,  9,  9, 11, 25,  3, 38,\n",
      "         8, 12,  7,  2, 14,  1, 21, 12,  5, 17, 25, 12, 18,  9])\n",
      "tensor([42,  9,  3, 11,  3, 15, 10, 32,  5,  5,  8, 14,  4,  3,  2, 31,  2, 36,\n",
      "        11, 17, 14,  2,  7, 13,  6,  5,  4,  7, 38, 20, 32, 12])\n",
      "tensor([33, 28,  1, 17, 13, 17,  8, 23, 38,  1, 10, 11, 28,  2, 18,  1, 38,  8,\n",
      "         7, 38, 17,  4, 31,  3, 17,  5,  8, 10,  9, 41,  1, 26])\n",
      "tensor([13, 10, 20, 10, 11,  7,  8, 13, 39, 25,  1, 31,  9, 12,  2, 12,  4, 17,\n",
      "        31,  9,  5,  7, 22,  9, 31,  1,  7, 18, 12, 22, 13, 10])\n",
      "tensor([10, 10, 40,  2, 10, 10,  7, 11,  1, 14, 10, 38, 32,  7,  8, 25, 11, 38,\n",
      "        17, 14, 10,  4, 25, 35, 12, 11, 12, 10, 25, 18, 29,  2])\n",
      "tensor([36,  7, 38,  5, 11, 13, 13,  4, 31, 12,  5, 22,  5, 24,  9,  7, 42,  1,\n",
      "         3,  1,  9, 12, 36, 10,  2, 16, 15, 10, 38,  1,  5, 35])\n",
      "tensor([12,  8, 24, 25, 15,  9, 11, 17,  5, 38,  5, 12, 26,  5, 10, 30, 25, 36,\n",
      "         1, 12, 10, 14, 36,  7, 34,  9, 12, 35,  1,  4,  1, 12])\n",
      "tensor([25, 31, 20, 25, 11,  8, 35,  3, 34, 13,  4, 25, 31,  2, 12, 21,  4, 25,\n",
      "        30, 35, 10,  4, 41, 27,  4,  3, 11, 35, 13, 13, 35,  7])\n",
      "tensor([ 2, 38, 10,  5,  2, 38, 25, 24, 16, 35, 13, 39, 36, 13, 32, 30, 14,  9,\n",
      "         3,  5,  8,  5,  6, 15, 38, 11, 19, 30,  4, 19, 18, 31])\n",
      "tensor([14, 12, 38, 12,  8,  2,  2, 38, 35,  8, 12,  2, 31, 10, 31,  8,  1, 10,\n",
      "         1, 10,  5, 14,  4, 36, 38, 32, 13, 34,  2, 33, 11,  3])\n",
      "tensor([ 9,  3,  2,  9, 12, 12, 13, 30, 13, 41, 15, 12, 22,  2, 13, 38, 29,  2,\n",
      "         1,  5,  8, 38, 39, 31, 20,  1, 10, 12, 19,  5, 37, 38])\n",
      "tensor([ 8, 17,  4, 38,  8, 25,  9, 33,  1, 29, 18, 24, 11,  4,  7, 13, 20,  1,\n",
      "        38,  5, 12, 26, 13, 15, 33, 18,  2, 37, 26, 11, 10,  2])\n",
      "tensor([38, 38, 17, 10,  7,  5, 12,  8, 13, 14,  5, 31, 20, 13,  9, 17, 31,  5,\n",
      "        15, 33,  8,  4,  9, 18,  5,  5,  2,  4, 22, 13,  9, 26])\n",
      "tensor([ 4,  1, 16, 13,  1,  4,  9, 10, 14, 25,  2, 28,  5,  1,  5, 21,  8,  4,\n",
      "        10,  2, 16, 13,  7,  1,  7, 35,  7,  4, 17,  1, 14, 13])\n",
      "tensor([37, 23,  7,  8,  4,  1,  4, 25, 12, 25,  4, 13, 35,  7,  8,  7,  2, 38,\n",
      "        30, 10,  2,  3, 13, 33,  6, 15, 16, 25, 10, 26, 38, 24])\n",
      "tensor([15, 11,  7, 14,  6, 14,  1, 24, 28,  1, 42,  5, 25, 23, 37,  7, 14, 13,\n",
      "        25,  9, 38,  2, 11,  4,  1,  2, 10,  3,  3, 14, 38, 36])\n",
      "tensor([24, 12,  7,  5,  7,  2, 17, 25, 36, 13, 25,  3,  3,  1,  9, 18,  1, 18,\n",
      "        31, 10, 10,  7, 24, 13, 35, 33, 13, 14,  3, 23, 33,  5])\n",
      "tensor([ 5,  8, 34, 35, 38, 26,  0,  2, 31, 25, 31, 16,  3, 23, 29, 33, 35, 12,\n",
      "        17, 11, 10, 10, 35, 15, 23, 13, 40,  7,  8,  1,  8,  4])\n",
      "tensor([38,  6, 10, 14, 12, 13,  5, 34,  8,  3, 13, 22, 15, 31,  1, 21, 18,  3,\n",
      "        25, 23,  7, 39,  3,  5, 20, 12, 16,  0,  1,  6,  4, 35])\n",
      "tensor([35, 38,  3,  3, 36,  6, 17,  7, 13, 38, 35, 12, 21, 11,  0,  8,  8,  9,\n",
      "         1,  2, 17, 38,  3, 13,  5, 11, 13,  4,  0,  2,  8,  4])\n",
      "tensor([19, 18, 33,  1,  0, 39,  8, 10, 10, 12, 10,  5, 25, 18,  1, 13, 17, 18,\n",
      "         9, 33,  2,  1, 30, 12, 31, 40, 18,  4,  7, 18,  9,  1])\n",
      "tensor([ 5, 31, 42,  1,  9,  9, 15, 33, 33,  5, 17, 27, 12, 25,  2, 38,  9, 40,\n",
      "        33,  9, 35,  9, 12, 11,  1,  4, 12, 34,  5,  2, 18,  9])\n",
      "tensor([15,  0, 18,  2,  5, 26, 10, 13, 10,  4,  8, 26,  2,  9, 10,  3, 25, 41,\n",
      "        16,  8, 14,  7, 10, 23, 13,  9, 12, 12,  8, 38, 15,  9])\n",
      "tensor([11, 38, 14,  1, 25,  1, 20,  9, 26, 23,  2, 38, 12,  3, 20, 12, 13, 38,\n",
      "        10, 22,  3, 28, 35, 17, 11, 18,  4, 33, 17,  9,  9, 25])\n",
      "tensor([36,  6,  3, 13, 29,  5,  7,  4,  4,  2, 38, 20,  4,  8, 22,  3,  3,  8,\n",
      "        14,  4,  7, 18, 28, 13, 18,  1, 34, 25,  7,  4, 16, 11])\n",
      "tensor([38, 10,  2, 22,  2,  8,  8, 38, 22, 25, 38, 17, 15, 38,  1,  2,  6,  7,\n",
      "        18,  9,  3, 10, 11,  8, 31, 11,  9, 16, 17,  8,  8, 23])\n",
      "tensor([ 2,  3,  2,  5,  2,  5, 22, 38, 22, 22, 13,  3, 22, 14, 12,  2, 24, 14,\n",
      "        10, 42,  7, 15,  8, 12, 18, 13, 10,  1, 12,  4,  7,  8])\n",
      "tensor([12, 13, 38, 17,  7,  2,  4, 39, 20, 36,  9,  1, 12,  9, 28,  5, 38,  2,\n",
      "         2,  1,  9, 20, 12,  1,  3, 41,  9, 13, 37, 13, 33,  4])\n",
      "tensor([35, 35,  5, 35, 25,  9,  2, 27, 17, 35, 12, 18, 37, 31, 38, 16,  1, 38,\n",
      "        10, 12, 35, 10, 10, 20,  2,  7, 18,  1, 38, 33,  2,  3])\n",
      "tensor([18, 16, 42, 38, 13,  1,  2,  1, 24, 19,  4, 24,  1, 11,  7, 12, 18,  8,\n",
      "         6,  1,  2, 31, 12, 12, 25, 15, 13, 13,  1, 16,  5, 32])\n",
      "tensor([38,  8, 25, 35,  8, 25,  8, 40,  2,  5,  3, 38, 31,  5, 38,  5, 10,  3,\n",
      "        38, 13,  5, 26,  1,  2,  8,  8,  7, 25, 18, 10, 25, 13])\n",
      "tensor([ 5, 26, 15, 18,  2, 17, 10, 39,  2,  1,  9, 35, 25,  4,  4, 18, 14,  8,\n",
      "         3, 17,  2, 25,  2, 10, 40, 13, 11, 25, 25,  1, 17, 36])\n",
      "tensor([23, 35,  3, 23,  9, 38, 38,  2, 18, 14, 38,  7, 25,  5,  2, 12,  4, 38,\n",
      "        11, 28, 28,  1, 12, 20,  1, 25, 39, 25, 13,  8,  3, 19])\n",
      "tensor([20,  9, 25, 11,  7, 28,  2, 35, 17, 12,  5, 11, 31,  1, 31, 10, 35, 18,\n",
      "        14, 15,  2, 12,  5,  2, 15, 18, 23,  9, 30, 24, 29, 18])\n",
      "tensor([ 1, 10, 35,  7,  2, 17, 39,  7, 24, 38,  1,  5, 16,  9, 26,  2,  4,  8,\n",
      "        13, 10, 41, 13, 38,  9, 25, 13, 12,  5,  1, 36,  8,  2])\n",
      "tensor([ 2,  2, 31, 11,  9, 19, 22,  4,  7, 31, 12, 26,  2, 26, 18,  9,  3,  5,\n",
      "         9,  5,  2, 10, 38,  9,  7, 14, 25, 25, 36, 24,  4, 18])\n",
      "tensor([36,  3, 24,  4, 12,  5, 40,  2,  3, 20, 15, 13, 13, 20,  5,  1, 39,  2,\n",
      "        35, 22,  5, 37, 11,  2, 10, 19, 28, 12,  5, 37,  9,  8])\n",
      "tensor([33, 36, 18, 13, 12, 13,  5, 13,  2,  7, 11,  8,  5, 25,  1, 38, 13, 19,\n",
      "         3, 28,  2,  9, 11, 28,  2, 14, 10, 12, 33, 12, 11,  1])\n",
      "tensor([ 1, 11, 15,  9, 38, 13,  4, 13,  5,  1, 10,  4, 13, 10, 12, 39,  3, 38,\n",
      "        31, 28,  2,  4,  2, 41,  6, 20, 35,  9, 12,  3,  9,  1])\n",
      "tensor([13,  4,  7, 31, 23, 22, 11,  9, 10, 13,  6, 26,  9, 26,  1,  3, 33, 31,\n",
      "        16, 40, 40, 29,  5,  5, 18, 15,  3, 13, 12, 10, 10, 28])\n",
      "tensor([15, 25,  7, 31, 35,  5, 32, 16, 33, 17, 10, 21, 14, 12,  4,  3,  4,  8,\n",
      "         1, 18,  3,  9, 29,  5,  3, 31,  3, 40, 30,  5, 19,  3])\n",
      "tensor([38,  6,  2, 35,  5, 13, 17,  5, 38, 13,  7,  3,  4, 34, 38,  9, 33, 38,\n",
      "        32,  3, 38, 38, 42, 25, 25, 14, 34, 26,  1, 12,  4, 33])\n",
      "tensor([10,  3, 10, 10, 13, 15, 11,  3,  1,  2, 18,  4, 33, 20,  3, 15, 33, 38,\n",
      "         2,  5, 13, 14, 13,  1, 25, 28, 24,  5, 25, 38,  4, 13])\n",
      "tensor([ 2, 38, 24, 25,  9,  5,  1, 22,  5,  7,  6, 12, 16,  3, 35,  1,  9,  7,\n",
      "         8, 30, 23,  2, 39, 23, 10, 11,  1,  2, 15, 17,  7,  2])\n",
      "tensor([18, 11,  9, 20,  2,  9,  3,  1, 11,  4, 10,  6, 10,  3, 25,  5, 22,  3,\n",
      "        12, 25, 13, 10, 35, 10, 35, 38, 24, 13, 35, 25, 38,  1])\n",
      "tensor([26,  7, 35, 11, 39,  8,  4, 10, 20, 31,  8, 31, 13,  5, 12, 35, 25, 12,\n",
      "        33, 32,  7, 10])\n",
      "Accuracy of the quantized model on the test set: 95.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95.55819477434679,\n",
       " [33,\n",
       "  44,\n",
       "  49,\n",
       "  50,\n",
       "  66,\n",
       "  72,\n",
       "  78,\n",
       "  79,\n",
       "  114,\n",
       "  127,\n",
       "  147,\n",
       "  163,\n",
       "  198,\n",
       "  237,\n",
       "  252,\n",
       "  265,\n",
       "  283,\n",
       "  304,\n",
       "  314,\n",
       "  335,\n",
       "  374,\n",
       "  421,\n",
       "  443,\n",
       "  455,\n",
       "  459,\n",
       "  475,\n",
       "  492,\n",
       "  496,\n",
       "  501,\n",
       "  527,\n",
       "  537,\n",
       "  550,\n",
       "  596,\n",
       "  599,\n",
       "  637,\n",
       "  660,\n",
       "  661,\n",
       "  749,\n",
       "  764,\n",
       "  804,\n",
       "  806,\n",
       "  829,\n",
       "  858,\n",
       "  883,\n",
       "  914,\n",
       "  943,\n",
       "  1008,\n",
       "  1025,\n",
       "  1065,\n",
       "  1079,\n",
       "  1121,\n",
       "  1131,\n",
       "  1171,\n",
       "  1200,\n",
       "  1210,\n",
       "  1276,\n",
       "  1317,\n",
       "  1390,\n",
       "  1402,\n",
       "  1422,\n",
       "  1431,\n",
       "  1440,\n",
       "  1475,\n",
       "  1477,\n",
       "  1489,\n",
       "  1514,\n",
       "  1524,\n",
       "  1573,\n",
       "  1583,\n",
       "  1597,\n",
       "  1628,\n",
       "  1709,\n",
       "  1713,\n",
       "  1759,\n",
       "  1763,\n",
       "  1812,\n",
       "  1819,\n",
       "  1844,\n",
       "  1898,\n",
       "  1910,\n",
       "  2002,\n",
       "  2023,\n",
       "  2025,\n",
       "  2054,\n",
       "  2057,\n",
       "  2069,\n",
       "  2109,\n",
       "  2112,\n",
       "  2120,\n",
       "  2154,\n",
       "  2157,\n",
       "  2188,\n",
       "  2191,\n",
       "  2220,\n",
       "  2228,\n",
       "  2258,\n",
       "  2275,\n",
       "  2336,\n",
       "  2342,\n",
       "  2370,\n",
       "  2379,\n",
       "  2397,\n",
       "  2425,\n",
       "  2428,\n",
       "  2446,\n",
       "  2494,\n",
       "  2538,\n",
       "  2559,\n",
       "  2577,\n",
       "  2601,\n",
       "  2615,\n",
       "  2678,\n",
       "  2687,\n",
       "  2741,\n",
       "  2748,\n",
       "  2753,\n",
       "  2812,\n",
       "  2836,\n",
       "  2847,\n",
       "  2864,\n",
       "  2886,\n",
       "  2887,\n",
       "  2896,\n",
       "  2911,\n",
       "  2924,\n",
       "  2931,\n",
       "  2946,\n",
       "  2980,\n",
       "  2993,\n",
       "  3011,\n",
       "  3025,\n",
       "  3043,\n",
       "  3086,\n",
       "  3147,\n",
       "  3157,\n",
       "  3159,\n",
       "  3163,\n",
       "  3172,\n",
       "  3220,\n",
       "  3250,\n",
       "  3294,\n",
       "  3303,\n",
       "  3319,\n",
       "  3341,\n",
       "  3363,\n",
       "  3434,\n",
       "  3468,\n",
       "  3485,\n",
       "  3523,\n",
       "  3525,\n",
       "  3564,\n",
       "  3567,\n",
       "  3593,\n",
       "  3597,\n",
       "  3630,\n",
       "  3643,\n",
       "  3655,\n",
       "  3695,\n",
       "  3704,\n",
       "  3723,\n",
       "  3725,\n",
       "  3727,\n",
       "  3739,\n",
       "  3744,\n",
       "  3745,\n",
       "  3752,\n",
       "  3778,\n",
       "  3793,\n",
       "  3806,\n",
       "  3833,\n",
       "  3857,\n",
       "  3860,\n",
       "  3907,\n",
       "  3911,\n",
       "  3922,\n",
       "  3930,\n",
       "  3960,\n",
       "  4036,\n",
       "  4088,\n",
       "  4105,\n",
       "  4130,\n",
       "  4147,\n",
       "  4185,\n",
       "  4219,\n",
       "  4245,\n",
       "  4270,\n",
       "  4271,\n",
       "  4281,\n",
       "  4306,\n",
       "  4314,\n",
       "  4325,\n",
       "  4334,\n",
       "  4335,\n",
       "  4383,\n",
       "  4400,\n",
       "  4434,\n",
       "  4437,\n",
       "  4443,\n",
       "  4449,\n",
       "  4456,\n",
       "  4479,\n",
       "  4504,\n",
       "  4509,\n",
       "  4511,\n",
       "  4535,\n",
       "  4562,\n",
       "  4579,\n",
       "  4585,\n",
       "  4605,\n",
       "  4617,\n",
       "  4634,\n",
       "  4639,\n",
       "  4658,\n",
       "  4690,\n",
       "  4716,\n",
       "  4786,\n",
       "  4795,\n",
       "  4803,\n",
       "  4833,\n",
       "  4849,\n",
       "  4853,\n",
       "  4874,\n",
       "  4897,\n",
       "  4967,\n",
       "  4983,\n",
       "  5008,\n",
       "  5057,\n",
       "  5073,\n",
       "  5113,\n",
       "  5149,\n",
       "  5180,\n",
       "  5182,\n",
       "  5233,\n",
       "  5251,\n",
       "  5280,\n",
       "  5313,\n",
       "  5319,\n",
       "  5397,\n",
       "  5476,\n",
       "  5507,\n",
       "  5518,\n",
       "  5519,\n",
       "  5521,\n",
       "  5562,\n",
       "  5565,\n",
       "  5574,\n",
       "  5622,\n",
       "  5625,\n",
       "  5629,\n",
       "  5637,\n",
       "  5641,\n",
       "  5667,\n",
       "  5693,\n",
       "  5705,\n",
       "  5761,\n",
       "  5779,\n",
       "  5799,\n",
       "  5807,\n",
       "  5808,\n",
       "  5844,\n",
       "  5872,\n",
       "  5890,\n",
       "  5892,\n",
       "  5895,\n",
       "  5910,\n",
       "  5924,\n",
       "  5934,\n",
       "  5966,\n",
       "  5972,\n",
       "  6000,\n",
       "  6028,\n",
       "  6068,\n",
       "  6085,\n",
       "  6090,\n",
       "  6127,\n",
       "  6129,\n",
       "  6177,\n",
       "  6199,\n",
       "  6200,\n",
       "  6220,\n",
       "  6253,\n",
       "  6255,\n",
       "  6258,\n",
       "  6278,\n",
       "  6310,\n",
       "  6324,\n",
       "  6334,\n",
       "  6341,\n",
       "  6356,\n",
       "  6418,\n",
       "  6504,\n",
       "  6509,\n",
       "  6529,\n",
       "  6544,\n",
       "  6580,\n",
       "  6600,\n",
       "  6612,\n",
       "  6613,\n",
       "  6645,\n",
       "  6693,\n",
       "  6731,\n",
       "  6732,\n",
       "  6766,\n",
       "  6768,\n",
       "  6782,\n",
       "  6788,\n",
       "  6838,\n",
       "  6862,\n",
       "  6874,\n",
       "  6878,\n",
       "  6910,\n",
       "  6920,\n",
       "  6933,\n",
       "  6957,\n",
       "  7006,\n",
       "  7049,\n",
       "  7073,\n",
       "  7081,\n",
       "  7085,\n",
       "  7087,\n",
       "  7122,\n",
       "  7142,\n",
       "  7147,\n",
       "  7225,\n",
       "  7244,\n",
       "  7276,\n",
       "  7330,\n",
       "  7460,\n",
       "  7461,\n",
       "  7473,\n",
       "  7506,\n",
       "  7516,\n",
       "  7525,\n",
       "  7553,\n",
       "  7571,\n",
       "  7574,\n",
       "  7593,\n",
       "  7597,\n",
       "  7671,\n",
       "  7712,\n",
       "  7713,\n",
       "  7725,\n",
       "  7886,\n",
       "  7896,\n",
       "  7907,\n",
       "  7918,\n",
       "  7928,\n",
       "  7967,\n",
       "  7977,\n",
       "  7988,\n",
       "  8007,\n",
       "  8022,\n",
       "  8038,\n",
       "  8051,\n",
       "  8052,\n",
       "  8058,\n",
       "  8076,\n",
       "  8187,\n",
       "  8198,\n",
       "  8208,\n",
       "  8218,\n",
       "  8273,\n",
       "  8278,\n",
       "  8284,\n",
       "  8292,\n",
       "  8295,\n",
       "  8305,\n",
       "  8308,\n",
       "  8316,\n",
       "  8332,\n",
       "  8337,\n",
       "  8348,\n",
       "  8352,\n",
       "  8355,\n",
       "  8376,\n",
       "  8422,\n",
       "  8427,\n",
       "  8449,\n",
       "  8460,\n",
       "  8483,\n",
       "  8499,\n",
       "  8510,\n",
       "  8517,\n",
       "  8549,\n",
       "  8585,\n",
       "  8587,\n",
       "  8611,\n",
       "  8624,\n",
       "  8679,\n",
       "  8702,\n",
       "  8714,\n",
       "  8727,\n",
       "  8770,\n",
       "  8818,\n",
       "  8859,\n",
       "  8918,\n",
       "  8923,\n",
       "  8945,\n",
       "  8964,\n",
       "  8974,\n",
       "  8978,\n",
       "  9068,\n",
       "  9073,\n",
       "  9076,\n",
       "  9117,\n",
       "  9158,\n",
       "  9174,\n",
       "  9183,\n",
       "  9200,\n",
       "  9222,\n",
       "  9242,\n",
       "  9254,\n",
       "  9270,\n",
       "  9334,\n",
       "  9350,\n",
       "  9411,\n",
       "  9429,\n",
       "  9475,\n",
       "  9484,\n",
       "  9497,\n",
       "  9509,\n",
       "  9545,\n",
       "  9546,\n",
       "  9609,\n",
       "  9628,\n",
       "  9638,\n",
       "  9661,\n",
       "  9688,\n",
       "  9733,\n",
       "  9769,\n",
       "  9792,\n",
       "  9835,\n",
       "  9880,\n",
       "  9961,\n",
       "  10016,\n",
       "  10024,\n",
       "  10028,\n",
       "  10030,\n",
       "  10067,\n",
       "  10137,\n",
       "  10173,\n",
       "  10204,\n",
       "  10205,\n",
       "  10210,\n",
       "  10230,\n",
       "  10292,\n",
       "  10300,\n",
       "  10318,\n",
       "  10328,\n",
       "  10365,\n",
       "  10367,\n",
       "  10381,\n",
       "  10384,\n",
       "  10398,\n",
       "  10401,\n",
       "  10454,\n",
       "  10480,\n",
       "  10489,\n",
       "  10502,\n",
       "  10524,\n",
       "  10536,\n",
       "  10546,\n",
       "  10564,\n",
       "  10573,\n",
       "  10584,\n",
       "  10586,\n",
       "  10675,\n",
       "  10676,\n",
       "  10698,\n",
       "  10730,\n",
       "  10782,\n",
       "  10783,\n",
       "  10820,\n",
       "  10836,\n",
       "  10845,\n",
       "  10866,\n",
       "  10878,\n",
       "  10908,\n",
       "  10927,\n",
       "  10928,\n",
       "  10968,\n",
       "  10971,\n",
       "  10995,\n",
       "  11016,\n",
       "  11069,\n",
       "  11070,\n",
       "  11089,\n",
       "  11128,\n",
       "  11132,\n",
       "  11142,\n",
       "  11170,\n",
       "  11173,\n",
       "  11178,\n",
       "  11183,\n",
       "  11201,\n",
       "  11212,\n",
       "  11351,\n",
       "  11366,\n",
       "  11375,\n",
       "  11391,\n",
       "  11393,\n",
       "  11403,\n",
       "  11433,\n",
       "  11435,\n",
       "  11438,\n",
       "  11515,\n",
       "  11520,\n",
       "  11529,\n",
       "  11543,\n",
       "  11556,\n",
       "  11564,\n",
       "  11593,\n",
       "  11616,\n",
       "  11617,\n",
       "  11625,\n",
       "  11643,\n",
       "  11650,\n",
       "  11654,\n",
       "  11709,\n",
       "  11741,\n",
       "  11746,\n",
       "  11756,\n",
       "  11817,\n",
       "  11822,\n",
       "  11825,\n",
       "  11866,\n",
       "  11872,\n",
       "  11904,\n",
       "  11925,\n",
       "  11980,\n",
       "  12024,\n",
       "  12032,\n",
       "  12040,\n",
       "  12071,\n",
       "  12089,\n",
       "  12103,\n",
       "  12111,\n",
       "  12163,\n",
       "  12181,\n",
       "  12215,\n",
       "  12226,\n",
       "  12227,\n",
       "  12264,\n",
       "  12271,\n",
       "  12276,\n",
       "  12346,\n",
       "  12354,\n",
       "  12364,\n",
       "  12369,\n",
       "  12377,\n",
       "  12396,\n",
       "  12412,\n",
       "  12423,\n",
       "  12481,\n",
       "  12489,\n",
       "  12518,\n",
       "  12585,\n",
       "  12608,\n",
       "  12614,\n",
       "  12616,\n",
       "  12627])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkpoint_path = 'traffic_sign_model_quantized_final.pth'\n",
    "checkpoint_path = 'quant_traffic_sign_model.pth'\n",
    "model = QuantizedTrafficSignModel_1()\n",
    "model = quantize_model(model, test_loader)\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "\n",
    "model.eval()\n",
    "print(model)\n",
    "test_quantized_model(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[175, 172, 173,  ..., 144, 148, 131],\n",
      "          [176, 175, 176,  ..., 176, 174, 172],\n",
      "          [175, 176, 173,  ..., 180, 180, 178],\n",
      "          ...,\n",
      "          [168, 165, 165,  ..., 170, 169, 173],\n",
      "          [167, 169, 167,  ..., 168, 166, 168],\n",
      "          [168, 166, 166,  ..., 168, 168, 171]],\n",
      "\n",
      "         [[140, 138, 139,  ..., 115, 122, 106],\n",
      "          [143, 141, 142,  ..., 144, 142, 140],\n",
      "          [142, 143, 141,  ..., 145, 145, 144],\n",
      "          ...,\n",
      "          [138, 135, 136,  ..., 138, 137, 140],\n",
      "          [137, 135, 132,  ..., 136, 137, 140],\n",
      "          [136, 135, 136,  ..., 139, 139, 141]],\n",
      "\n",
      "         [[117, 117, 119,  ...,  99,  98,  86],\n",
      "          [116, 116, 118,  ..., 120, 121, 121],\n",
      "          [118, 118, 115,  ..., 121, 123, 121],\n",
      "          ...,\n",
      "          [118, 116, 118,  ..., 116, 117, 119],\n",
      "          [117, 115, 114,  ..., 114, 118, 116],\n",
      "          [113, 111, 120,  ..., 116, 118, 115]]]], dtype=torch.uint8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "image_path = veri_path+'\\\\Test\\\\00000.png'\n",
    "input_image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "input_image = cv2.imread(os.path.join(image_path))\n",
    "input_image = cv2.resize(input_image,(32,32))\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "input_tensor = transform(input_image)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    outputs = model(input_tensor)\n",
    "\n",
    "final_output = outputs['output']\n",
    "_, predicted_class = torch.max(final_output, 1)\n",
    "plt.imshow(input_image)\n",
    "plt.title(f'Predicted class: {predicted_class.item()}')\n",
    "\n",
    "conv1_output = outputs['image'].int_repr()\n",
    "print(conv1_output)\n",
    "num_values = conv1_output.numel()\n",
    "#kernel = conv1_output.int_repr()\n",
    "#out_channels = conv1_output.shape[1] \n",
    "#image_size = (conv1_output.shape[2], conv1_output.shape[3]) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = veri_path+'\\\\Test\\\\00003.png'\n",
    "input_image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "input_tensor = transform(input_image)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    outputs = model(input_tensor)\n",
    "\n",
    "tensor_in = outputs['image'].int_repr()\n",
    "tensor_in = tensor_in.squeeze(0)\n",
    "string_tensor_in_arr = []\n",
    "string_tensor_in_mat = []\n",
    "# Prepare the output data\n",
    "with open('ahuhu.txt', \"w\") as outfile:\n",
    "    for row in range(tensor_in.shape[1]):\n",
    "        string_tensor_in_arr = []\n",
    "        for col in range(tensor_in.shape[2]):\n",
    "            # Extract the 3-channel pixel values\n",
    "            pixel_values = tensor_in[:, row, col]\n",
    "            # Convert each channel value to hex and concatenate\n",
    "            hex_pixel = ''.join(f\"{round(pixel_values[i].item()):02x}\" for i in reversed(range(tensor_in.shape[0])))\n",
    "            outfile.write(hex_pixel + \"\\n\")\n",
    "            string_tensor_in_arr.append(hex_pixel)\n",
    "        string_tensor_in_mat.append(string_tensor_in_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def convert_to_64bit(hex_values, output_file, split_size=16):\n",
    "\n",
    "    hex_values.reverse()  # Reverse order\n",
    "    hex_data = \"\".join(hex_values)  # Concatenate into a single string\n",
    "\n",
    "    # Split into fixed-size chunks (e.g., 16 characters per line)\n",
    "    chunks = [hex_data[i:i+split_size] for i in range(0, len(hex_data), split_size)]\n",
    "\n",
    "    chunks.reverse()\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(chunks) + \"\\n\")  # Write output with new lines\n",
    "\n",
    "# Path to your Test directory\n",
    "\n",
    "test_dir = os.path.join(veri_path+'\\\\Test\\\\')\n",
    "\n",
    "# Prepare your transform once\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Find all PNGs, sort by filename (so 00000.png, 00001.png, …)\n",
    "png_files = sorted(glob.glob(os.path.join(test_dir, \"*.png\")))\n",
    "pixel_array = []\n",
    "# Open output file once (will overwrite if exists)\n",
    "#with open(\"all_images_hex.txt\", \"w\") as outfile:\n",
    "for png_path in png_files:\n",
    "    # Optional: write a header for each image\n",
    "    # outfile.write(f\"# {os.path.basename(png_path)}\\n\")\n",
    "\n",
    "    # Load & run through model\n",
    "    input_image = cv2.imread(os.path.join(png_path))\n",
    "    input_image = cv2.resize(input_image,(32,32))\n",
    "    input_tensor = transform(input_image).unsqueeze(0)  # add batch dim\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "        # Extract your tensor and drop the batch dim\n",
    "    tensor_in = outputs['image'].int_repr().squeeze(0)\n",
    "\n",
    "        # Loop rows x cols\n",
    "    for row in range(tensor_in.shape[1]):\n",
    "        for col in range(tensor_in.shape[2]):\n",
    "            # pull out the 3 channels (C, H, W)\n",
    "            pixel = tensor_in[:, row, col]\n",
    "            # pack into hex (BGR → RGB reversed)\n",
    "            hex_pixel = ''.join(f\"{int(pixel[i].item()):02x}\" for i in reversed(range(pixel.shape[0])))\n",
    "            pixel_array.append(hex_pixel)\n",
    "            #outfile.write(hex_pixel + \"\\n\")\n",
    "convert_to_64bit(pixel_array,\"quantize_test_image_bitstream.mem\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_images_hex.txt\", \"w\") as outfile:\n",
    "    for png_path in png_files:\n",
    "        # Optional: write a header for each image\n",
    "        # outfile.write(f\"# {os.path.basename(png_path)}\\n\")\n",
    "\n",
    "        # Load & run through model\n",
    "        img = Image.open(png_path)\n",
    "        input_tensor = transform(img).unsqueeze(0)  # add batch dim\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "\n",
    "        # Extract your tensor and drop the batch dim\n",
    "        tensor_in = outputs['image'].int_repr().squeeze(0)\n",
    "\n",
    "        # Loop rows x cols\n",
    "        for row in range(tensor_in.shape[1]):\n",
    "            for col in range(tensor_in.shape[2]):\n",
    "                # pull out the 3 channels (C, H, W)\n",
    "                pixel = tensor_in[:, row, col]\n",
    "                # pack into hex (BGR → RGB reversed)\n",
    "                hex_pixel = ''.join(f\"{int(pixel[i].item()):02x}\" for i in reversed(range(pixel.shape[0])))\n",
    "                outfile.write(hex_pixel + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING IN 1 CONV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array to file converter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def save_array_to_file(array, file_path, file_format=\"txt\", fl_t=\"int_type\"):\n",
    "    \"\"\"\n",
    "    Saves a NumPy array or PyTorch tensor to a file with one value per line if the format is 'txt'.\n",
    "\n",
    "    Args:\n",
    "        array (np.ndarray or torch.Tensor): Input array or tensor.\n",
    "        file_path (str): Path to save the file.\n",
    "        file_format (str): Format of the file ('txt' or 'npy'). Default is 'txt'.\n",
    "    \"\"\"\n",
    "    # Convert PyTorch tensor to NumPy array if necessary\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        array = array.cpu().numpy()  # Convert tensor to NumPy array\n",
    "\n",
    "    # Ensure input is now a NumPy array\n",
    "    if not isinstance(array, np.ndarray):\n",
    "        raise ValueError(\"Input must be a NumPy array or a PyTorch tensor.\")\n",
    "\n",
    "    # Flatten the array to ensure one value per line\n",
    "    array = array.flatten()\n",
    "\n",
    "    # Save the array in the specified format\n",
    "    if file_format == \"txt\":\n",
    "        if(fl_t == \"float_type\"):\n",
    "            np.savetxt(file_path, array, fmt=\"%.6f\")\n",
    "        else:\n",
    "            np.savetxt(file_path, array, fmt=\"%d\")\n",
    "    elif file_format == \"npy\":\n",
    "        np.save(file_path, array)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use 'txt' or 'npy'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 40, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "print(outputs['pool1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string_by_two(s):\n",
    "    return [s[i:i+2] for i in range(0, len(s), 2)]\n",
    "\n",
    "def hex_difference_acceptable(hex1, hex2):\n",
    "    return abs(int(hex1, 16) - int(hex2, 16)) <= 1\n",
    "\n",
    "def compare_files(file1, file2):\n",
    "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "        lines1 = f1.readlines()\n",
    "        lines2 = f2.readlines()\n",
    "    \n",
    "    if len(lines1) != len(lines2):\n",
    "       print(\"Error: Files have different number of lines\")\n",
    "       return\n",
    "    \n",
    "    for line_num, (line1, line2) in enumerate(zip(lines1, lines2), start=1):\n",
    "        parts1 = split_string_by_two(line1.strip())\n",
    "        parts2 = split_string_by_two(line2.strip())\n",
    "        \n",
    "        if len(parts1) != len(parts2):\n",
    "            print(f\"Error in line {line_num}: Mismatched string lengths after splitting\")\n",
    "            continue\n",
    "        \n",
    "        for idx, (p1, p2) in enumerate(zip(parts1, parts2)):\n",
    "            if not hex_difference_acceptable(p1, p2):\n",
    "                print(f\"Error in line {line_num}, segment {idx+1}: {p1} vs {p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in line 16, segment 22: 80 vs 7e\n",
      "Error in line 25, segment 29: 8a vs 88\n",
      "Error in line 37, segment 34: 8d vs 8b\n",
      "Error in line 38, segment 34: 8f vs 8d\n",
      "Error in line 45, segment 34: 8d vs 8b\n",
      "Error in line 47, segment 29: 87 vs 85\n",
      "Error in line 47, segment 32: 86 vs 84\n",
      "Error in line 49, segment 21: 74 vs 76\n",
      "Error in line 51, segment 32: 86 vs 84\n",
      "Error in line 63, segment 39: 85 vs 83\n",
      "Error in line 67, segment 39: 81 vs 7f\n",
      "Error in line 75, segment 8: 84 vs 82\n",
      "Error in line 81, segment 34: 81 vs 7f\n",
      "Error in line 85, segment 34: 7f vs 7d\n",
      "Error in line 87, segment 34: 7f vs 7d\n",
      "Error in line 93, segment 21: 7c vs 7e\n",
      "Error in line 147, segment 35: 81 vs 7f\n",
      "Error in line 163, segment 21: 81 vs 83\n",
      "Error in line 163, segment 34: 77 vs 75\n",
      "Error in line 164, segment 21: 85 vs 87\n"
     ]
    }
   ],
   "source": [
    "hw_path = \"conv3_sw_rs.txt\"\n",
    "sw_path = \"C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\conv3_hw_rs.txt\"\n",
    "compare_files(hw_path,sw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedTrafficSignModel_1(\n",
      "  (quant): Quantize(scale=tensor([0.0292]), zero_point=tensor([128]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      "  (conv1): QuantizedConv2d(3, 40, kernel_size=(3, 3), stride=(1, 1), scale=0.04566194862127304, zero_point=128)\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(40, 20, kernel_size=(1, 1), stride=(1, 1), scale=0.05472395196557045, zero_point=128)\n",
      "  (conv3): QuantizedConv2d(20, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.05733923614025116, zero_point=128)\n",
      "  (conv4): QuantizedConv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.15728062391281128, zero_point=128)\n",
      "  (conv5): QuantizedConv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.3021003305912018, zero_point=128)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv6): QuantizedConv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), scale=0.22387517988681793, zero_point=128)\n",
      "  (conv7): QuantizedConv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), scale=0.24758994579315186, zero_point=128)\n",
      "  (conv8): QuantizedConv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.5544191002845764, zero_point=128)\n",
      "  (conv9): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.776608407497406, zero_point=128)\n",
      "  (dropout): QuantizedDropout(p=0.15, inplace=False)\n",
      "  (fc): QuantizedLinear(in_features=64, out_features=43, scale=0.6604684591293335, zero_point=128, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line_to_9_lines(line):\n",
    "    line = line.strip()\n",
    "    part_len = len(line) // 9\n",
    "    return [line[i:i + part_len] for i in range(0, len(line), part_len)]\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line_num, line in enumerate(infile, 1):\n",
    "            if len(line.strip()) % 9 != 0:\n",
    "                print(f\"Warning: Line {line_num} length not divisible by 9. Skipping.\")\n",
    "                continue\n",
    "            parts = split_line_to_9_lines(line)\n",
    "            for part in parts:\n",
    "                outfile.write(part + '\\n')\n",
    "\n",
    "# Usage\n",
    "input_path = 'C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\conv8_lb_hw_rs.txt'\n",
    "output_path = 'conv8_lb.txt'\n",
    "process_file(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Tensor converted and saved to ahuhu.txt\n"
     ]
    }
   ],
   "source": [
    "# Load the tensor from the .pt file\n",
    "tensor_in = outputs['image'].int_repr()  # Assuming tensor is saved as a PyTorch tensor\n",
    "# Squeeze the batch dimension to get a (3, 32, 32) tensor\n",
    "tensor_in = tensor_in.squeeze(0)\n",
    "string_tensor_in_arr = []\n",
    "string_tensor_in_mat = []\n",
    "# Prepare the output data\n",
    "with open('ahuhu.txt', \"w\") as outfile:\n",
    "    for row in range(tensor_in.shape[1]):\n",
    "        string_tensor_in_arr = []\n",
    "        for col in range(tensor_in.shape[2]):\n",
    "            # Extract the 3-channel pixel values\n",
    "            pixel_values = tensor_in[:, row, col]\n",
    "            # Convert each channel value to hex and concatenate\n",
    "            hex_pixel = ''.join(f\"{round(pixel_values[i].item()):02x}\" for i in reversed(range(tensor_in.shape[0])))\n",
    "            outfile.write(hex_pixel + \"\\n\")\n",
    "            string_tensor_in_arr.append(hex_pixel)\n",
    "        string_tensor_in_mat.append(string_tensor_in_arr)\n",
    "print(len(string_tensor_in_mat[0]))\n",
    "print(f\"Tensor converted and saved to ahuhu.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128, 128, 128, 130, 128, 128, 128, 128, 128, 147, 128, 128, 128, 128,\n",
      "        132, 128, 128, 128, 147, 128, 128, 128, 128, 128, 128, 128, 128, 130,\n",
      "        128, 128, 128, 144, 140, 135, 153, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 149, 159, 128, 128, 135, 128, 128, 133, 129, 128, 130,\n",
      "        128, 128, 128, 128, 131, 128, 139, 128], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(outputs['conv9'].int_repr().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 43)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def process_hex_file(filename):\n",
    "    pixel_arrays = []  # List to store pixel arrays\n",
    "    reversed_arrays = []  # List to store reversed pixel arrays\n",
    "    line_count = 0\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove any trailing newline or spaces\n",
    "            pixel_array = [int(line[i:i+2], 16) for i in range(0, len(line), 2)]\n",
    "            pixel_arrays.append(pixel_array)\n",
    "\n",
    "            # Reverse the pixel array\n",
    "            reversed_array = pixel_array[::-1]\n",
    "            reversed_arrays.append(reversed_array)\n",
    "            line_count += 1  # Increment line count\n",
    "\n",
    "    return pixel_arrays, reversed_arrays, line_count\n",
    "\n",
    "# Example usage\n",
    "#filename = \"conv10_sw_rs.txt\" # Change this to your actual file\n",
    "filename = \"C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\fc_hw_rs.txt\" # Change this to your actual file\n",
    "pixels, reversed_indices, line_count = process_hex_file(filename)\n",
    "\n",
    "#print(\"Pixel Arrays:\", pixels)\n",
    "#print(\"Reversed Position Arrays:\", reversed_indices)\n",
    "\n",
    "sw_rs = []\n",
    "line = 0 \n",
    "reversed_indices = np.array(reversed_indices)\n",
    "print(reversed_indices.shape)\n",
    "size = int(math.sqrt(line_count))\n",
    "# Reshape the 1D array into a 2D array\n",
    "sw_rs = reversed_indices.reshape(size,size,43)\n",
    "#for i in range(64):\n",
    "#    print(sw_rs[0,0,i])\n",
    "#    print(sw_rs_a[0,0,(63-i)])  \n",
    "#    print(\"DGG\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-14,  33, -50,  -2,  57,  42,  52,   3,  42,  45, -28, -37,  50, -24,\n",
      "        -91,  40,  63,  -9,  38,  -2,  62, -63,  39, -23,  39,  27, -42, -35,\n",
      "         57, -19, -25,  41, -34, -18,  17, -15, -30,  31, -64,  29, -65,   2,\n",
      "         55,  92, -30,  21,  54, -41,  25, -19, -64, -74,   2, -54,  41, -37,\n",
      "        -29, -53, -17,   1,  25, -10, -36, -25], dtype=torch.int8)\n",
      "tensor([128, 128, 142, 134, 128, 128, 128, 150, 128, 128, 128, 128, 128, 156,\n",
      "        128, 128, 128, 128, 128, 128, 128, 153, 149, 128, 128, 128, 128, 128,\n",
      "        128, 128, 137, 130, 128, 128, 144, 128, 128, 128, 128, 128, 128, 128,\n",
      "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 129, 147, 128,\n",
      "        128, 128, 128, 155, 154, 128, 129, 136], dtype=torch.uint8)\n",
      "-7691\n",
      "tensor(594.0006, grad_fn=<SubBackward0>)\n",
      "tensor([124, 126,  98, 142, 136, 147, 150, 137, 110, 144, 134, 136, 148, 124,\n",
      "        129, 136, 174, 110, 125, 130, 128, 115,  98, 140, 115, 115, 115, 134,\n",
      "        139, 116, 123, 106, 138, 132, 132, 136, 127, 121, 121, 123, 143, 129,\n",
      "        135], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "s_weight = model.fc.weight().q_scale()\n",
    "s_out =  outputs['fc'].q_scale()\n",
    "s_activate = outputs['conv9'].q_scale()\n",
    "s_comb = (s_activate * s_weight) / s_out\n",
    "input_a = model.fc.weight().int_repr()[0]\n",
    "input_b = outputs['conv9'].int_repr().detach().squeeze()\n",
    "print(input_a)\n",
    "print(input_b)\n",
    "np_a = input_a.numpy()\n",
    "np_b = input_b.numpy()\n",
    "print((np.sum(np_a*np_b)))\n",
    "conv_rs = (np.sum(np_a*np_b))\n",
    "print(conv_rs*s_comb + bias_test[0] + 128 - 128*s_comb*(np.sum(model.fc.weight().int_repr().detach().numpy())))\n",
    "print(outputs['fc'].int_repr()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.27878539309741\n"
     ]
    }
   ],
   "source": [
    "print(-50*142*s_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_weight = model.fc.weight().q_scale()\n",
    "s_out =  outputs['fc'].q_scale()\n",
    "s_activate = outputs['conv9'].q_scale()\n",
    "s_comb = (s_activate * s_weight) / s_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.9557e-01,  5.5463e-01,  8.4016e-02, -1.7062e-01,  2.1408e-01,\n",
      "         1.4210e-01, -8.1082e-02,  1.2986e-01,  2.3609e-01,  2.9384e-01,\n",
      "        -1.4124e-01,  3.1225e-01,  2.7473e-01,  9.7089e-02, -1.8765e-01,\n",
      "        -2.5755e-01,  2.7361e-03, -1.5861e-01,  4.2488e-01, -2.6764e-01,\n",
      "        -1.8805e-02, -1.9140e-01, -5.8698e-02,  1.7885e-02, -4.0144e-02,\n",
      "         1.2747e-01, -2.3411e-01, -2.6816e-01,  1.9999e-01, -1.5998e-01,\n",
      "         4.7738e-02,  7.6011e-02,  5.1697e-02,  9.6101e-02, -2.2342e-01,\n",
      "         1.3657e-01,  1.0910e-01, -3.3402e-01,  2.8662e-01, -1.1794e-01,\n",
      "         9.1729e-02,  3.0949e-04, -3.4415e-01], grad_fn=<DivBackward0>)\n",
      "-7691\n",
      "124.27257\n"
     ]
    }
   ],
   "source": [
    "weights_float = input_a.dequantize().to(torch.float32) \n",
    "weights_np = weights_float.detach().numpy()\n",
    "bias_test = model.fc.bias() / s_out \n",
    "print(bias_test)\n",
    "print(conv_rs)\n",
    "macc_coeff = conv_rs*s_comb + bias_test + 128 - 128*s_comb*(np.sum(weights_np))\n",
    "print(macc_coeff.detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_hex_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv10_sw_rs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Change this to your actual file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#filename = \"C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\conv4_hw_rs.txt\" # Change this to your actual file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m pixels, reversed_indices, line_count \u001b[38;5;241m=\u001b[39m process_hex_file(filename)\n\u001b[0;32m      4\u001b[0m sw_rs_a \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_hex_file' is not defined"
     ]
    }
   ],
   "source": [
    "filename = \"conv5_sw_rs.txt\" # Change this to your actual file\n",
    "#filename = \"C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\conv4_hw_rs.txt\" # Change this to your actual file\n",
    "pixels, reversed_indices, line_count = process_hex_file(filename)\n",
    "sw_rs_a = []\n",
    "line = 0 \n",
    "reversed_indices = np.array(reversed_indices)\n",
    "print(reversed_indices.shape)\n",
    "size = int(math.sqrt(line_count))\n",
    "# Reshape the 1D array into a 2D array\n",
    "sw_rs_a = reversed_indices.reshape(size,size,64)\n",
    "\n",
    "print(sw_rs_a[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 48 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming reversed_indices is already defined and has 64 slice\n",
    "\n",
    "# Create a figure with 8 rows × 8 columns (since 8×8=64)\n",
    "fig, axes = plt.subplots(8, 6, figsize=(10, 15))\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through all 64 depth slices\n",
    "for i in range(48):\n",
    "    ax = axes[i]  # Select subplot\n",
    "    ax.imshow(sw_rs[:, :, i], cmap='gray', aspect='auto')  # Display as grayscale\n",
    "    ax.set_title(f\"Slice {i}\")  # Title for each slice\n",
    "    ax.axis(\"off\")  # Hide axis for better visualization\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2700x300 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "def extract_and_display_images(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # Convert first 2 characters of each line to a grayscale value\n",
    "    pixel_values = [int(f\"0x{line[:2]}\", 16) for line in lines]\n",
    "\n",
    "    # Group every 9 pixels into a 3x3 image\n",
    "    images = [pixel_values[i:i+9][::-1] for i in range(0, len(pixel_values), 9)]\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(3 * len(images), 3))\n",
    "\n",
    "    if len(images) == 1:\n",
    "        axs = [axs]  # Ensure axs is iterable\n",
    "\n",
    "    for idx, img_data in enumerate(images):\n",
    "        img_array = [img_data[i:i+3] for i in range(0, 9, 3)]  # Reshape to 3x3\n",
    "        img = Image.new(\"L\", (3, 3))\n",
    "        img.putdata(img_data)\n",
    "        axs[idx].imshow(img, cmap=\"gray\", aspect='auto')\n",
    "        axs[idx].axis(\"off\")\n",
    "        axs[idx].set_title(f\"Image {idx+1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "extract_and_display_images('conv8_lb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of hex values: 0x10005dc9db (Decimal: 68725623259)\n",
      "Sum with bias: 0x1000966ddb\n",
      "Convert value: 0x100096\n",
      "0x38\n",
      "0x10005d\n",
      "0x5101dac\n"
     ]
    }
   ],
   "source": [
    "def sum_hex_values(file_path):\n",
    "    total = 0\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                hex_value = line.strip()\n",
    "                if hex_value:\n",
    "                    total += int(hex_value, 16)\n",
    "        print(f\"Sum of hex values: {hex(total)} (Decimal: {total})\")\n",
    "        print(f\"Sum with bias: {hex(total+3712000)}\")\n",
    "        print(f\"Convert value: {hex(int((total+3712000)/65536))}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found.\")\n",
    "    except ValueError:\n",
    "        print(\"Error: Invalid hex value in file.\")\n",
    "    return total\n",
    "\n",
    "# Example usage:\n",
    "file_path = \"C:\\\\Users\\\\lckd2\\\\CNN-main\\\\CNN-main.sim\\\\sim_1\\\\behav\\\\xsim\\\\conv4_macc_rs.txt\"  # Replace with your actual file path\n",
    "macc_rs = sum_hex_values(file_path)\n",
    "print(hex(int(3712000/65536)))\n",
    "print(hex(int(macc_rs/65536)))\n",
    "print(hex((int(macc_rs*(81/65536)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output written to cv8_debug.txt\n"
     ]
    }
   ],
   "source": [
    "def process_hex_out_file(input_filename, output_filename, start_line=0, end_line=None):\n",
    "    with open(input_filename, 'r') as file:\n",
    "        hex_values = [line.strip() for line in file if line.strip()]\n",
    "    \n",
    "    # Apply line range filtering\n",
    "    hex_values = hex_values[start_line:end_line] if end_line is not None else hex_values[start_line:]\n",
    "    \n",
    "    # Step 1: Extract 8 LSB bits (last two characters of each hex value)\n",
    "    lsb_values = [value[-2:] for value in hex_values]\n",
    "    \n",
    "    # Step 2: Arrange in a 48 (length) x 24 (width) 2D array (column-wise filling)\n",
    "    length, width = 48, 24*3*3\n",
    "    array_2d = [[''] * width for _ in range(length)]\n",
    "    \n",
    "    for i, val in enumerate(lsb_values):\n",
    "        row = i % length  # Iterate over length first\n",
    "        col = i // length # Then move to width\n",
    "        if col < width:\n",
    "            array_2d[row][col] = val\n",
    "    \n",
    "    # Step 3: Reverse each row before concatenation\n",
    "    concatenated_rows = [''.join(row[::-1]) for row in array_2d]\n",
    "    \n",
    "    # Step 4: Write output to a file\n",
    "    with open(output_filename, 'w') as output_file:\n",
    "        for row in concatenated_rows:\n",
    "            output_file.write(row + '\\n')\n",
    "    \n",
    "    print(f\"Processing complete. Output written to {output_filename}\")\n",
    "\n",
    "# Example usage\n",
    "process_hex_out_file(\"tsr_fpga_weights_19_1_latest.txt\", \"cv8_debug.txt\", start_line=23192, end_line=23192 + 48*24*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07689473811655813\n",
      "-42824.0\n",
      "0.0016741524901089401\n",
      "-0.07689473811655813\n",
      "106.5877059279351\n"
     ]
    }
   ],
   "source": [
    "# Prepare a list to store the differences for each c_out\n",
    "differences = []\n",
    "diff_arr = []\n",
    "sw_val_arr = []\n",
    "tensor_in = outputs['conv8']\n",
    "tensor_weight = model.conv9.weight()\n",
    "tensor_bias   = model.conv9.bias()\n",
    "tensor_out    = outputs['conv9']\n",
    "rtl_sim_arr   = []\n",
    "have_relu = 0\n",
    "for i in range(tensor_out.shape[2]):\n",
    "    for j in range(tensor_out.shape[3]):\n",
    "        differences = []\n",
    "        sw_sims = []\n",
    "        rtl_sims = []\n",
    "# Loop over c_out from 0 to 39\n",
    "        for c_out in range(tensor_out.shape[1]):\n",
    "            # Extract weights, bias, and input window for the current c_out\n",
    "            test_weight = tensor_weight[c_out].int_repr()\n",
    "            test_bias = tensor_bias[c_out]\n",
    "            test_window = tensor_in[:,:, i:i+tensor_weight.shape[2], j:j+tensor_weight.shape[3]].int_repr()\n",
    "            #test_window = tensor_in.int_repr() - 128\n",
    "            # Dequantize and convert to NumPy\n",
    "            weights_float = test_weight.dequantize().to(torch.float32)  # Dequantize and convert to float32\n",
    "            bias_float = test_bias.to(torch.float32)                    # Convert bias to float32\n",
    "            image_float = test_window.dequantize().to(torch.float32)    # Convert image to float32 if needed\n",
    "            \n",
    "            # Convert to NumPy arrays\n",
    "            weights_np = weights_float.detach().numpy()\n",
    "            bias_np = bias_float.detach().numpy()\n",
    "            image_np = image_float.detach().numpy()\n",
    "            # Perform the convolution\n",
    "            conv_rs = np.sum(weights_np * image_np) \n",
    "            #FIXME:\n",
    "            # Scale and bias calculations\n",
    "            s_weight = tensor_weight.q_scale()\n",
    "            s_out = tensor_out.q_scale()\n",
    "            s_activate = tensor_in.q_scale()\n",
    "            s_comb = (s_activate * s_weight) / s_out\n",
    "            #print(weights_np[0][0][0]*image_np[0][0][0])\n",
    "            bias_test = bias_np / s_out \n",
    "\n",
    "            macc_coeff = conv_rs*s_comb + bias_test + 128 - 128*s_comb*(np.sum(weights_np))\n",
    "            #print(bias_test + 128 - 128*s_comb*(np.sum(weights_np)))\n",
    "            # Calculate ReLU and RTL simulation\n",
    "            if(macc_coeff < 0):\n",
    "                print(\"NO ROI CAC CHAU OI\")\n",
    "            relu = max(macc_coeff, 128)\n",
    "            \n",
    "            if have_relu:\n",
    "                rtl_sim = round(relu)\n",
    "            else:\n",
    "                rtl_sim = round(macc_coeff)\n",
    "            rtl_sims.append(f\"{rtl_sim:02x}\") \n",
    "            # Software simulation result\n",
    "            test_output = tensor_out[0][c_out][i][j].int_repr().item()\n",
    "            #test_output = tensor_out[0][c_out].int_repr().item()\n",
    "            sw_sim = int(test_output)\n",
    "            if(j == 0 and i == 0 and c_out == 0):\n",
    "            #if(c_out == 8 and  j == 0 and i == 0): #36 3 0\n",
    "                print(bias_test)\n",
    "                print(conv_rs)\n",
    "                print(s_comb)\n",
    "                print(bias_test)\n",
    "                print(macc_coeff)\n",
    "                #print(weights_np[:,0,0])\n",
    "                #print(image_np[0,:,0,0])\n",
    "            #    for x in range(48):\n",
    "            #        if(x == 20):\n",
    "            #            print(\"AAAA\")\n",
    "            #            print(round(weights_np[x,0,0]))\n",
    "            #        print(round(weights_np[x,0,0]*image_np[0,x,0,0]))\n",
    "            #    print(f\"SUM = {np.sum(weights_np*image_np)}\")\n",
    "                #print(bias_test + 128 - 128*s_comb*(np.sum(weights_np)))\n",
    "                #print(bias_test + 128 - 128*s_comb*(np.sum(weights_np)))\n",
    "                #print(conv_rs*s_comb)\n",
    "                #print(hex(rtl_sim))\n",
    "                #print(hex(sw_sim))\n",
    "            #print(bias_test + 128 - 128*s_comb*(np.sum(weights_np)))\n",
    "            # Calculate the difference and store it\n",
    "            difference = abs(sw_sim - rtl_sim)\n",
    "            differences.append(difference)\n",
    "            sw_sims.append(sw_sim)\n",
    "            #error_percentage = (differences / sw_sim ) * 100\n",
    "            # Optionally print the results for debugging\n",
    "           # print(f\"c_out: {c_out}, SW Sim: {sw_sim}, RTL Sim: {rtl_sim}, Difference: {difference}\") \n",
    "        rtl_sim_arr.append(\"\".join(reversed(rtl_sims)))  \n",
    "        # After the loop, you can analyze or save the differences as needed\n",
    "        diff_arr.append(sum(differences))\n",
    "        sw_val_arr.append(sum(sw_sims))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3)\n",
      "()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[208], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(weights_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]):  \u001b[38;5;66;03m# kernel_height\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(weights_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):  \u001b[38;5;66;03m# in_channels\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m             kernel_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mclip(weights_np[fil, cha, row], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16)\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Chuẩn bị hệ số MACC (Multiply-Accumulate Coefficient)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m macc_coeff_list\u001b[38;5;241m.\u001b[39mappend(s_activate\u001b[38;5;241m*\u001b[39ms_weight\u001b[38;5;241m/\u001b[39ms_out)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "kernel_list = []\n",
    "bias_list = []\n",
    "macc_coeff_list = []\n",
    "layer_scale_list = []\n",
    "\n",
    "# Chuẩn bị kernel và bias\n",
    "print(weights_np.shape)\n",
    "print(bias_np.shape)\n",
    "bias_list.append(bias_np / s_out)\n",
    "for fil in range(weights_np.shape[0]):\n",
    "    for row in range(weights_np.shape[2]):  # kernel_height\n",
    "        for cha in range(weights_np.shape[1]):  # in_channels\n",
    "            kernel_list.append(np.clip(weights_np[fil, cha, row], -128, 128).tolist().astype(np.int16).tolist()) #FIXME\n",
    "\n",
    "# Chuẩn bị hệ số MACC (Multiply-Accumulate Coefficient)\n",
    "macc_coeff_list.append(s_activate*s_weight/s_out)\n",
    "\n",
    "# Chuẩn bị scale của layer\n",
    "layer_scale_list.append(s_out)\n",
    "\n",
    "# Kết quả\n",
    "print(\n",
    "    f'Num kernel      : {len(kernel_list)}\\n'\n",
    "    f'Num bias        : {len(bias_list)}\\n'\n",
    "    f'Num macc_coeff  : {len(macc_coeff_list)}\\n'\n",
    "    f'Num layer_scale : {len(layer_scale_list)}\\n'\n",
    "    f'Total weights   : {len(kernel_list) + len(bias_list) + len(macc_coeff_list) + len(layer_scale_list)}'\n",
    ")\n",
    "print(kernel_list)\n",
    "# Write to file\n",
    "byte_array = bytearray()\n",
    "bias_qformat = {'m': 8, 'n': 8, 'signed': 1}\n",
    "scale_qformat = {'m': 2, 'n': 16, 'signed': 0}\n",
    "\n",
    "# Hàm chuyển đổi số thực sang fixed-point\n",
    "def to_fixed_point(val, qformat):\n",
    "    m, n, signed = qformat['m'], qformat['n'], qformat['signed']\n",
    "    scale = 2 ** n\n",
    "    max_val = (2 ** (m + n - 1) - 1) if signed else (2 ** (m + n) - 1)\n",
    "    min_val = -(2 ** (m + n - 1)) if signed else 0\n",
    "    \n",
    "    val_fixed = int(round(val * scale))\n",
    "    val_clipped = max(min(val_fixed, max_val), min_val)\n",
    "    return val_clipped\n",
    "\n",
    "# Ghi kernel_list\n",
    "for val in kernel_list:\n",
    "    byte_array.extend((int(val) & 0xffff).to_bytes(length=2, byteorder='little', signed=True))\n",
    "\n",
    "# Ghi bias_list\n",
    "for val in bias_list:\n",
    "    fixed_val = to_fixed_point(val, bias_qformat)\n",
    "    byte_array.extend(fixed_val.to_bytes(length=2, byteorder='little', signed=True))\n",
    "\n",
    "# Ghi macc_coeff_list và layer_scale_list\n",
    "for val in macc_coeff_list + layer_scale_list:\n",
    "    fixed_val = to_fixed_point(val, scale_qformat)\n",
    "    byte_array.extend(fixed_val.to_bytes(length=2, byteorder='little', signed=False))\n",
    "\n",
    "# Lưu byte array vào file\n",
    "with open(\"test_macc_coeff.txt\", \"wb\") as f:\n",
    "    f.write(byte_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1356927271.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[188], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    bias_qformat = {'m': 8, 'n': 8, 'signed': 1}\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "byte_array = bytearray()\n",
    "bias_qformat = {'m': 8, 'n': 8, 'signed': 1}\n",
    "scale_qformat = {'m': 2, 'n': 16, 'signed': 0}\n",
    "\n",
    "for val in :\n",
    "    byte_array.extend((val.item() & 0xffff).to_bytes(length=2, byteorder='little'))\n",
    "\n",
    "for val in bias_list:\n",
    "    byte_array.extend(int(f'{FixedPoint(val, **bias_qformat):04x}', 16).to_bytes(length=2, byteorder='little'))\n",
    "\n",
    "for val in macc_coeff_list + layer_scale_list:\n",
    "    byte_array.extend(int(f'{FixedPoint(val, **scale_qformat):04x}', 16).to_bytes(length=2, byteorder='little'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantize_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraffic_sign_model_quantized_final.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m QuantizedTrafficSignModel_1()\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m quantize_model(model, test_loader)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'quantize_model' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'traffic_sign_model_quantized_final.pth'\n",
    "model = QuantizedTrafficSignModel_1()\n",
    "model = quantize_model(model, test_loader)\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the quantized model on the test set: 95.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.55819477434679"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_quantized_model(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs['output']\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.max(labels, 1)[1]).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the quantized model on the test set: {accuracy:.1f}%')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "test_quantized_model(quantized_model_final, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lckd2\\AppData\\Local\\Temp\\ipykernel_237352\\1264006323.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path), strict=False)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'write_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m quantize_model(model, test_loader)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path), strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m write_weights(model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'write_weights' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'traffic_sign_model_quantized_final.pth'\n",
    "model = QuantizedTrafficSignModel()\n",
    "model = quantize_model(model, test_loader)\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "\n",
    "write_weights(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization info saved to quantization_info.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"quantization_info.txt\", \"w\") as f:\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.quantized.Conv2d, nn.quantized.Linear)):\n",
    "            f.write(f\"Layer: {name}\\n\")\n",
    "            f.write(f\"  Scale: {module.scale}\\n\")\n",
    "            f.write(f\"  Zero Point: {module.zero_point}\\n\\n\")\n",
    "\n",
    "print(\"Quantization info saved to quantization_info.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights: 56,680\n"
     ]
    }
   ],
   "source": [
    "#SCRIPT TO GENERATE RTL CODE\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "def rtl_gen(model, rtl_path, fifo_factor=1):\n",
    "\n",
    "    conv1_layer_1 = model.conv1\n",
    "    pool1_layer_2 = model.pool1\n",
    "    conv2_layer_3 = model.conv2\n",
    "    conv3_layer_4 = model.conv3\n",
    "    conv4_layer_5 = model.conv4\n",
    "    conv5_layer_6 = model.conv5\n",
    "    pool2_layer_7 = model.pool2\n",
    "    conv6_layer_8 = model.conv6\n",
    "    conv7_layer_9 = model.conv7\n",
    "    conv8_layer_10 = model.conv8\n",
    "    conv9_layer_11 = model.conv9\n",
    "    fc1_layer_12 = model.fc\n",
    "\n",
    "    with open(rtl_path, 'w') as f:\n",
    "        f.write(\n",
    "            '`timescale 1ns / 1ps\\n'\n",
    "            '\\n'\n",
    "            'module tsr_model (\\n'\n",
    "            '    output [8*43-1:0] o_data,\\n'\n",
    "            '    output            o_valid,\\n'\n",
    "            '    output            fifo_rd_en,\\n'\n",
    "            '    input  [8*3-1:0]  i_data,\\n'\n",
    "            '    input             i_valid,\\n'\n",
    "            '    input             almost_full,\\n'\n",
    "            '    input  [15:0]     weight_wr_data,\\n'\n",
    "            '    input  [31:0]     weight_wr_addr,\\n'\n",
    "            '    input             weight_wr_en,\\n'\n",
    "            '    input             clk,\\n'\n",
    "            '    input             rst_n\\n'\n",
    "            ');\\n\\n'\n",
    "        )\n",
    "\n",
    "        in_size = (32,32)\n",
    "\n",
    "        # Encoder stages\n",
    "        for i, layer in enumerate([conv1_layer_1,pool1_layer_2,conv2_layer_3,conv3_layer_4,conv4_layer_5,conv5_layer_6,pool2_layer_7,conv6_layer_8,conv7_layer_9,conv8_layer_10,conv9_layer_11,fc1_layer_12]):\n",
    "            if(isinstance(layer,nn.Linear)):\n",
    "                in_channel = layer.in_features\n",
    "                out_channel = layer.out_features\n",
    "            else:\n",
    "                if(isinstance(layer,nn.MaxPool2d)):\n",
    "                    in_channel = pre_in_channel\n",
    "                    out_channel = pre_in_channel\n",
    "                else:\n",
    "                    in_channel = layer.in_channels\n",
    "                    out_channel = layer.out_channels\n",
    "                pre_in_channel = in_channel\n",
    "                kernel_size = layer.kernel_size\n",
    "                padding = layer.padding\n",
    "                dilation = layer.dilation\n",
    "                stride = layer.stride\n",
    "            layer_num = i \n",
    "            if layer_num == 0:\n",
    "                i_data = 'i_data'\n",
    "                i_valid = 'i_valid'\n",
    "                conv_fifo_rd_en = 'fifo_rd_en'\n",
    "            else:\n",
    "                i_data = f'fifo_rd_data_{layer_num-1}'\n",
    "                i_valid = f'~fifo_empty_{layer_num-1}'\n",
    "                conv_fifo_rd_en = f'fifo_rd_en_{layer_num-1}'\n",
    "\n",
    "            compute_factor = 'single'\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "\n",
    "                f.write(\n",
    "                    f'    // Conv {layer_num}\\n'\n",
    "                    f'    wire [8*{out_channel}-1:0] o_data_{layer_num};\\n'\n",
    "                    f'    wire o_valid_{layer_num};\\n'\n",
    "                    f'    wire fifo_almost_full_{layer_num};\\n'\n",
    "                    f'\\n'\n",
    "                    f'    conv #(\\n'\n",
    "                    f'        .UNROLL_MODE           (\"incha\"),\\n'\n",
    "                    f'        .IN_WIDTH              ({int(in_size[1])}),\\n'\n",
    "                    f'        .IN_HEIGHT             ({int(in_size[0])}),\\n'\n",
    "                    f'        .OUTPUT_MODE           (\"relu\"),\\n'\n",
    "                    f'        .COMPUTE_FACTOR        (\"{compute_factor}\"),\\n'\n",
    "                    f'        .KERNEL_0              ({kernel_size[0]}),\\n'\n",
    "                    f'        .KERNEL_1              ({kernel_size[1]}),\\n'\n",
    "                    f'        .PADDING_0             ({padding[0]}),\\n'\n",
    "                    f'        .PADDING_1             ({padding[1]}),\\n'\n",
    "                    f'        .DILATION_0            ({dilation[0]}),\\n'\n",
    "                    f'        .DILATION_1            ({dilation[1]}),\\n'\n",
    "                    f'        .STRIDE_0              ({stride[0]}),\\n'\n",
    "                    f'        .STRIDE_1              ({stride[1]}),\\n'\n",
    "                    f'        .IN_CHANNEL            ({in_channel}),\\n'\n",
    "                    f'        .OUT_CHANNEL           ({out_channel}),\\n'\n",
    "                    f'        .KERNEL_BASE_ADDR      (),\\n'\n",
    "                    f'        .BIAS_BASE_ADDR        (),\\n'\n",
    "                    f'        .MACC_COEFF_BASE_ADDR  (),\\n'\n",
    "                    f'        .LAYER_SCALE_BASE_ADDR ()\\n'\n",
    "                    f'    ) u_enc_{layer_num} (\\n'\n",
    "                    f'        .o_data                (o_data_{layer_num}),\\n'\n",
    "                    f'        .o_valid               (o_valid_{layer_num}),\\n'\n",
    "                    f'        .fifo_rd_en            ({conv_fifo_rd_en}),\\n'\n",
    "                    f'        .i_data                ({i_data}),\\n'\n",
    "                    f'        .i_valid               ({i_valid}),\\n'\n",
    "                    f'        .fifo_almost_full      (1\\'b0),\\n'\n",
    "                    f'        .weight_wr_data        (weight_wr_data),\\n'\n",
    "                    f'        .weight_wr_addr        (weight_wr_addr),\\n'\n",
    "                    f'        .weight_wr_en          (weight_wr_en),\\n'\n",
    "                    f'        .clk                   (clk),\\n'\n",
    "                    f'        .rst_n                 (rst_n)\\n'\n",
    "                    f'    );\\n\\n'\n",
    "                )\n",
    "                \n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                f.write(\n",
    "                    f'    // MaxPool {layer_num}\\n'\n",
    "                    f'    wire [8*{out_channel}-1:0] o_data_{layer_num};\\n'\n",
    "                    f'    wire o_valid_{layer_num};\\n'\n",
    "                    f'    wire fifo_almost_full_{layer_num};\\n'\n",
    "                    f'\\n'\n",
    "                    f'    max_pooling #(\\n'\n",
    "                    f'        .DATA_WIDTH               (8),\\n'\n",
    "                    f'        .IN_WIDTH                 ({int(in_size[1])}),\\n'\n",
    "                    f'        .IN_HEIGHT                ({int(in_size[0])}),\\n'\n",
    "                    f'        .IN_CHANNEL               ({in_channel}),\\n'       \n",
    "                    f'        .PADDING_0                ({padding[0]}),\\n'\n",
    "                    f'        .PADDING_1                ({padding[1]}),\\n'\n",
    "                    f'        .DILATION_0               ({dilation[0]}),\\n'\n",
    "                    f'        .DILATION_1               ({dilation[1]}),\\n'\n",
    "                    f'        .STRIDE_0                 ({stride[0]}),\\n'\n",
    "                    f'        .STRIDE_1                 ({stride[1]})\\n'\n",
    "                    f'    ) u_max_{layer_num} (\\n'\n",
    "                    f'        .o_data                   (o_data_{layer_num}),\\n'\n",
    "                    f'        .o_valid                  (o_valid_{layer_num}),\\n'\n",
    "                    f'        .fifo_rd_en               ({conv_fifo_rd_en}),\\n'\n",
    "                    f'        .i_data                   ({i_data}),\\n'\n",
    "                    f'        .i_valid                  ({i_valid}),\\n'\n",
    "                    f'        .fifo_almost_full         (1\\'b0),\\n'\n",
    "                    f'        .clk                      (clk),\\n'\n",
    "                    f'        .rst_n                    (rst_n)\\n'\n",
    "                    f'    );\\n\\n'\n",
    "                )\n",
    "\n",
    "            elif isinstance(layer,nn.Linear):\n",
    "                f.write(\n",
    "                    f'    // Fully connected {layer_num}\\n'\n",
    "                    f'    wire [8*{out_channel}-1:0] o_data_{layer_num};\\n'\n",
    "                    f'    wire o_valid_{layer_num};\\n'\n",
    "                    f'    wire fifo_almost_full_{layer_num};\\n'\n",
    "                    f'\\n'\n",
    "                    f'    fc #(\\n'\n",
    "                    f'        .IN_CHANNEL               ({in_channel}),\\n'\n",
    "                    f'        .OUT_CHANNEL              ({out_channel}),\\n'\n",
    "                    f'        .KERNEL_0                 (1)'\n",
    "                    f'        .KERNEL_1                 (1)'\n",
    "                    f'        .KERNEL_BASE_ADDR         (),\\n'\n",
    "                    f'        .BIAS_BASE_ADDR           (),\\n'\n",
    "                    f'        .MACC_COEFF_BASE_ADD      (),\\n'\n",
    "                    f'        .LAYER_SCALE_BASE_ADD     ()\\n'\n",
    "                    f'    ) u_fc_{layer_num} (\\n'\n",
    "                    f'        .o_data                (o_data_{layer_num}),\\n'\n",
    "                    f'        .o_valid               (o_valid_{layer_num}),\\n'\n",
    "                    f'        .fifo_rd_en            ({conv_fifo_rd_en}),\\n'\n",
    "                    f'        .i_data                ({i_data}),\\n'\n",
    "                    f'        .i_valid               ({i_valid}),\\n'\n",
    "                    f'        .fifo_almost_full      (1\\'b0),\\n'\n",
    "                    f'        .weight_wr_data        (weight_wr_data),\\n'\n",
    "                    f'        .weight_wr_addr        (weight_wr_addr),\\n'\n",
    "                    f'        .weight_wr_en          (weight_wr_en),\\n'\n",
    "                    f'        .clk                   (clk),\\n'\n",
    "                    f'        .rst_n                 (rst_n)\\n'\n",
    "                    f'    );\\n\\n'\n",
    "                )\n",
    "                \n",
    "\n",
    "            in_size = tuple((in_size[_i] + 2 * padding[_i] - dilation[_i] * (kernel_size[_i] - 1) - 1) / stride[_i] + 1 for _i in range(2))\n",
    "            buffer_factor = fifo_factor * 2 if i == 0 else fifo_factor\n",
    "            buffer_depth = max(int(in_size[1]) * buffer_factor, 2)\n",
    "            f.write(\n",
    "                f'    wire [8*{out_channel}-1:0] fifo_rd_data_{layer_num};\\n'\n",
    "                f'    wire fifo_empty_{layer_num};\\n'\n",
    "                f'    wire fifo_rd_en_{layer_num};\\n'\n",
    "                f'\\n'\n",
    "                f'    fifo_single_read #(\\n'\n",
    "                f'        .DATA_WIDTH        (8 * {out_channel}),\\n'\n",
    "                f'        .DEPTH             ({buffer_depth}),\\n'\n",
    "                f'        .ALMOST_FULL_THRES (10)\\n'\n",
    "                f'    ) u_fifo_{layer_num} (\\n'\n",
    "                f'        .rd_data           (fifo_rd_data_{layer_num}),\\n'\n",
    "                f'        .empty             (fifo_empty_{layer_num}),\\n'\n",
    "                f'        .full              (),\\n'\n",
    "                f'        .almost_full       (fifo_almost_full_{layer_num}),\\n'\n",
    "                f'        .wr_data           (o_data_{layer_num}),\\n'\n",
    "                f'        .wr_en             (o_valid_{layer_num}),\\n'\n",
    "                f'        .rd_en             (fifo_rd_en_{layer_num}),\\n'\n",
    "                f'        .rst_n             (rst_n),\\n'\n",
    "                f'        .clk               (clk)\\n'\n",
    "                f'    );\\n\\n'\n",
    "                )\n",
    "\n",
    "        f.write('endmodule\\n')\n",
    "\n",
    "def weight_addr_map(rtl_path):\n",
    "    with open(rtl_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    total_weights = 0\n",
    "    kernel_0 = 0\n",
    "    kernel_1 = 0\n",
    "    in_channel = 0\n",
    "    out_channel = 0\n",
    "    output_mode = ''\n",
    "\n",
    "    # Kernel\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'KERNEL_0' in line:\n",
    "            kernel_0 = int(line.split('(')[1].split(')')[0])\n",
    "        if 'KERNEL_1' in line:\n",
    "            kernel_1 = int(line.split('(')[1].split(')')[0])\n",
    "        if 'IN_CHANNEL' in line:\n",
    "            in_channel = int(line.split('(')[1].split(')')[0])\n",
    "        if 'OUT_CHANNEL' in line:\n",
    "            out_channel = int(line.split('(')[1].split(')')[0])\n",
    "        if 'KERNEL_BASE_ADDR' in line:\n",
    "            num_weights = kernel_0 * kernel_1 * in_channel * out_channel\n",
    "            lines[i] = line.split('(')[0] + f'({total_weights}),  // Num kernel: {num_weights}\\n'\n",
    "            total_weights += num_weights\n",
    "\n",
    "    # Bias\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'OUT_CHANNEL' in line:\n",
    "            out_channel = int(line.split('(')[1].split(')')[0])\n",
    "        if 'BIAS_BASE_ADDR' in line:\n",
    "            lines[i] = line.split('(')[0] + f'({total_weights}),  // Num bias: {out_channel}\\n'\n",
    "            total_weights += out_channel\n",
    "\n",
    "    # MACC co-efficient\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'MACC_COEFF_BASE_ADDR' in line:\n",
    "            lines[i] = line.split('(')[0] + f'({total_weights}),  // Num macc_coeff: 1\\n'\n",
    "            total_weights += 1\n",
    "\n",
    "    # Layer scale\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'OUTPUT_MODE' in line:\n",
    "            output_mode = line.split('\"')[1]\n",
    "        if 'LAYER_SCALE_BASE_ADDR' in line and output_mode in ['dequant', 'sigmoid']:\n",
    "            lines[i] = line.split('(')[0] + f'({total_weights})   // Num layer_scale: 1\\n'\n",
    "            total_weights += 1\n",
    "\n",
    "    print(f'Total weights: {total_weights:,}')\n",
    "    with open(rtl_path, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # Initialize model\n",
    "    #model = QuantLaneNetQuantized().to('cpu')\n",
    "    #model = convert_quantized_model(model)\n",
    "    model = QuantizedTrafficSignModel_1()\n",
    "    # Write RTL file\n",
    "    rtl_gen(model=model, rtl_path='./model.v', fifo_factor=1)\n",
    "    weight_addr_map(rtl_path='./model.v')\n",
    "#add more number in QuantizedTrafficSignModel_1()\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Hook function to capture input and output\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Layer: {module}\")\n",
    "    print(f\"Input: {input}\")\n",
    "    print(f\"Output: {output}\")\n",
    "\n",
    "# Register the hook on the fc layer\n",
    "model.fc.register_forward_hook(hook_fn)\n",
    "\n",
    "# Pass a sample input through the model\n",
    "sample_input = torch.randn(1, 3, 32, 32)  # Adjust dimensions based on your model\n",
    "output = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Layer: {module}\")\n",
    "    print(f\"Input: {input}\")\n",
    "    print(f\"Output: {output}\")\n",
    "# Register the hook on the fc layer\n",
    "model.conv1.register_forward_hook(hook_fn)\n",
    "\n",
    "# Pass a sample input through the model\n",
    "sample_input = torch.randn(1, 3, 32, 32)  # Adjust dimensions based on your model\n",
    "output = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "def hook_fn(module, input, output):\n",
    "    print(f\"Layer: {module}\")\n",
    "    print(f\"Input: {input}\")\n",
    "    print(f\"Output: {output}\")\n",
    "# Register the hook on the fc layer\n",
    "model.fc.register_forward_hook(hook_fn)\n",
    "\n",
    "# Pass a sample input through the model\n",
    "sample_input = torch.randn(1, 3, 32, 32)  # Adjust dimensions based on your model\n",
    "output = model(sample_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
